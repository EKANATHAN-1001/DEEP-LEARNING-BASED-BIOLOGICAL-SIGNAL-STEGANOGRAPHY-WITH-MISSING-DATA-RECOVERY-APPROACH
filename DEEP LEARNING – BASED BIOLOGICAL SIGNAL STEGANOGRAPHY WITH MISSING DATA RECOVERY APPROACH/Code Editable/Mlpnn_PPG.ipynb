{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Iy3DAf325DI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gHnjoALH-rE",
        "outputId": "c312d709-01a1-49f5-a8f2-970713ff40d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyswarm in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pyswarm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ6sJNdIHtPc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pyswarm import pso\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB28IowTHvEo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/PPG_Data.csv')\n",
        "x_data = df['Time'][:200].values\n",
        "y_data = df['Data'][:200].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vUtezq7VIsxE",
        "outputId": "7db632e5-27f2-4db5-c782-5dbae4c76088"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDKklEQVR4nO3deXxb5ZU//s/V7k3e19jZHAjZHCBAMAxpIBuQoXTKtBTSIS0UGiZ8W6DTUk8pZfnRMDAF0mkb2ikt7QBlK3SBQkiAJECckARMQkICcTYn8b7Jlm2t9/fH1XN1ryzJkq3YlvJ5v155gS1ZvrJs3XPPOc95JFmWZRARERElEcNYHwARERFRvBjAEBERUdJhAENERERJhwEMERERJR0GMERERJR0GMAQERFR0mEAQ0REREmHAQwRERElHdNYH8Cp4vf7cfLkSWRlZUGSpLE+HCIiIoqBLMvo6elBWVkZDIbIeZaUDWBOnjyJioqKsT4MIiIiGoaGhgaUl5dHvD1lA5isrCwAyg/AbreP8dEQERFRLBwOByoqKtTzeCQpG8CIspHdbmcAQ0RElGSGav9gEy8RERElHQYwRERElHQYwBAREVHSYQBDRERESYcBDBERESUdBjBERESUdBjAEBERUdJhAENERERJhwEMERERJR0GMERERJR0GMAQERFR0mEAQ0REREmHAUwCvPzhcbxzoGWsD4OIiOi0wQBmhI539uHOFz7G7c/VjfWhEBERnTYYwIzQ5829AIDufg/8fnmMj4aIiOj0EFcAs27dOlRVVcFut8Nut6O6uhqvv/667j61tbW47LLLkJGRAbvdjgULFqC/v1+9vaOjAytWrIDdbkdOTg5uuukm9Pb26h5j9+7duOSSS2Cz2VBRUYGHH354BE/x1KpvDR77gNc3hkdCRER0+ogrgCkvL8dDDz2EXbt2YefOnbjssstw9dVXY+/evQCU4OXyyy/H0qVL8cEHH2DHjh247bbbYDAEv82KFSuwd+9ebNiwAa+++iq2bNmCW265Rb3d4XBg6dKlmDRpEnbt2oVHHnkE9957L37zm98k6CknVn2rU/3/fjcDGCIiotEgybI8orpHXl4eHnnkEdx000248MILsWTJEjzwwANh7/vpp59i5syZ2LFjB8477zwAwBtvvIErr7wSx48fR1lZGdatW4cf/ehHaGpqgsViAQD88Ic/xF/+8hfs378/5uNyOBzIzs5Gd3c37Hb7SJ5iVNf+uhbbD3cAAN6761KU56afsu9FRESU6mI9fw+7B8bn8+G5556D0+lEdXU1WlpasH37dhQVFeGiiy5CcXExvvCFL+C9995Tv6a2thY5OTlq8AIAixcvhsFgwPbt29X7LFiwQA1eAGDZsmU4cOAAOjs7Ix6Py+WCw+HQ/RsN2gzMgMc/Kt+TiIjodBd3ALNnzx5kZmbCarVi1apVeOWVVzBz5kwcOnQIAHDvvffi5ptvxhtvvIFzzz0XixYtwueffw4AaGpqQlFRke7xTCYT8vLy0NTUpN6nuLhYdx/xsbhPOGvWrEF2drb6r6KiIt6nFjfHgAdtvS714wEPS0hERESjIe4AZvr06airq8P27dtx6623YuXKldi3bx/8fiX78O1vfxvf/OY3cc455+Cxxx7D9OnT8bvf/S7hBx6qpqYG3d3d6r+GhoZT/j0PabIvANDPAIaIiGhUmOL9AovFgmnTpgEA5s2bhx07dmDt2rX44Q9/CACYOXOm7v4zZszAsWPHAAAlJSVoadEPfPN6vejo6EBJSYl6n+bmZt19xMfiPuFYrVZYrdZ4n86I1LfoV0+xiZeIiGh0jHgOjN/vh8vlwuTJk1FWVoYDBw7obv/ss88wadIkAEB1dTW6urqwa9cu9fa3334bfr8f8+fPV++zZcsWeDwe9T4bNmzA9OnTkZubO9LDTahDbSEBDDMwREREoyKuAKampgZbtmzBkSNHsGfPHtTU1GDTpk1YsWIFJEnC97//ffz85z/HSy+9hIMHD+LHP/4x9u/fj5tuugmAko25/PLLcfPNN+ODDz7A+++/j9tuuw1f+9rXUFZWBgC4/vrrYbFYcNNNN2Hv3r14/vnnsXbtWtx5552Jf/YjFFpCYg8MERHR6IirhNTS0oIbbrgBjY2NyM7ORlVVFdavX48lS5YAAG6//XYMDAzgjjvuQEdHB+bOnYsNGzagsrJSfYxnnnkGt912GxYtWgSDwYBrrrkGP//5z9Xbs7Oz8eabb2L16tWYN28eCgoKcM899+hmxYwXYoid1WSAy+tnCYmIiGiUjHgOzHh1qufA+PwyZtzzBtxeP+ZW5ODjhi7ce9VMfOPiKQn/XkRERKeLUz4H5nR3orMfbq8fFpMBlQUZAIB+zoEhIiIaFXGvQjrdrfnHp3jnQIvasDu1IAMZVuXHyCZeIiKi0cEAJk6N3QP4rDm4+mjepFykWYwA2MRLREQ0WhjAxOm2y6bha+crU35NRgPOrsjBL945CIBzYIiIiEYLA5g4nVmchTOLs3SfSzMrGRiWkIiIiEYHm3gTwGZWfowsIREREY0OBjAJIDIwDGCIiIhGBwOYBBBNvCwhERERjQ4GMAlgEz0wbOIlIiIaFQxgEiDYxMtBdkRERKOBAUwCcA4MERHR6GIAkwA2E0tIREREo4kBTAKkWQLLqL0MYIiIiEYDA5gEYBMvERHR6GIAkwCiidfl9cPvl8f4aIiIiFIfA5gEEE28AMtIREREo4EBTAKIJl6AZSQiIqLRwAAmAQwGCRaT8qPkNF4iIqJTjwFMggT3Q+IwOyIiolONAUyCcENHIiKi0cMAJkG4oSMREdHoYQCTIJwFQ0RENHoYwCRImplNvERERKOFAUyC2NgDQ0RENGoYwCRImqaE5PfLONjSC1nmVF4iIqJTgQFMgtgswQzME1vqsfjRzXhx5/ExPioiIqLUxAAmQdQMjMePPce7AQAfNXSN4RERERGlLgYwCRIMYHxo7B4AABzv7BvLQyIiIkpZDGASJE1TQmpSA5j+sTwkIiKilMUAJkHEKqSeAS9aepQA5kRnP/x+NvISERElGgOYBLEF5sA0dPRBxCxunx/NgWCGiIiIEocBTIKIHpjDbU7d5xs6WEYiIiJKNAYwCSICmJPd+oCloYONvERERInGACZBRBNv6Oy6kTTyur1+vLm3CY4Bz0gOjYiIKOUwgEkQ0cQrGA0SAKBhBEupX/7wOG75v134+cbPR3RsREREqYYBTIKkhQQws8vsAEZWQjrcrvTTNDnYCExERKTFACZBQjMw50/OAzCyElJ7rxsAN4gkIiIKxQAmQUIzMOdPUQKYxu5+eHz+YT1me68LADDgGd7XExERpSoGMAmSZtH/KKvKs2E1GeCXgZNdw8vCtDuZgSEiIgqHAUyCaEtIRoOEoiwbJuSmARh+GUmUkPoZwBAREekwgEkQbQmpKMsKo0FCRW46gOE18sqyjDa1hMQAhoiISIsBTIKIOTAAUJJtAwBU5CkZmOEspXa6fXB5ld4X9sAQERHpmcb6AFKFzRQMYEpFABPIwLy5txl9bh/Om5SH5VWlMT2eaOAFmIEhIiIKxQAmQQwGCRaTAW6vHyV2JfMyrSgTAPB5Sy8+b+nFU1uPYG7FpSgPBDbRtAX6XwAGMERERKFYQkog0QcjMjALpxfhvi/OwupLK3FmcSZkGXhp1/GYHqvDGQxg+j0+yKF7FBAREZ3GGMAkkAhgRA+M0SBh5UWT8f1lZ2H1pdMAAC/uPA6/PxiM+Pwyfv7W56itb9c9lraE5JcBj48BDBERkcAAJoEKs6wAgKmFGYNuWzarBFk2E0509WOrJliprW/Hoxs+w91/2aO7f7smAwMAA16WkYiIiAQGMAn02LVzsW7FuZhVlj3oNpvZiC+dPQEA8MLOBvXznzX3AACOtPfB7Q2uNmrTZGAAYMDNAIaIiEiIK4BZt24dqqqqYLfbYbfbUV1djddff129feHChZAkSfdv1apVusfYsWMHFi1ahJycHOTm5mLZsmX4+OOPdffZvXs3LrnkEthsNlRUVODhhx8ewVMcPdOKsnDFnMirjL56XgUA4I29Teju8wAA6lt7ASilpGMdTvW+7b0hGRgupSYiIlLFFcCUl5fjoYcewq5du7Bz505cdtlluPrqq7F37171PjfffDMaGxvVf9rgo7e3F5dffjkmTpyI7du347333kNWVhaWLVsGj0c5oTscDixduhSTJk3Crl278Mgjj+Dee+/Fb37zmwQ95bEze4Id04uz4Pb6seXzVgDAodZg0FKv+f92Z0gGhiUkIiIiVVzLqK+66irdxw8++CDWrVuHbdu2YdasWQCA9PR0lJSUhP36/fv3o6OjA/fffz8qKpRsxE9+8hNUVVXh6NGjmDZtGp555hm43W787ne/g8ViwaxZs1BXV4dHH30Ut9xyy3Ce47ghSRLmTc7FgeYe7D3pwFVzy9QMDKAPZkIzMP0sIREREamG3QPj8/nw3HPPwel0orq6Wv38M888g4KCAsyePRs1NTXo6wtOoZ0+fTry8/Px5JNPwu12o7+/H08++SRmzJiByZMnAwBqa2uxYMECWCwW9euWLVuGAwcOoLOzM+LxuFwuOBwO3b/xaHagP2bvyW70DHjQ0hPMtGiDmbZBJSQGMERERELcg+z27NmD6upqDAwMIDMzE6+88gpmzpwJALj++usxadIklJWVYffu3bjrrrtw4MABvPzyywCArKwsbNq0CV/60pfwwAMPAADOOOMMrF+/HiaTcihNTU2YMmWK7nsWFxert+Xm5oY9rjVr1uC+++6L9+mMullldgDAvpMOXcYFAA4FAhi/X0ZHoIRUkGlBW6+bGzoSERFpxJ2BmT59Ourq6rB9+3bceuutWLlyJfbt2wcAuOWWW7Bs2TLMmTMHK1aswB//+Ee88sorqK+vBwD09/fjpptuwsUXX4xt27bh/fffx+zZs7F8+XL09w9vx2ahpqYG3d3d6r+Ghoahv2gMTC/JgtEgod3pVpdT56abASg9MLIso6vfAzEqpixHmerLJl4iIqKguDMwFosF06YpQ9nmzZuHHTt2YO3atfj1r3896L7z588HABw8eBCVlZV49tlnceTIEdTW1sJgUGKnZ599Frm5ufjrX/+Kr33taygpKUFzc7PuccTHkXprAMBqtcJqtcb7dEadzWzEtMJMHGjuwd8/PgkAuHR6EV7+6AS6+z3ocLrR2aeUj7LTzMiyKS+Ri028REREqhHPgfH7/XC5XGFvq6urAwCUlipLi/v6+mAwGCBJUvAAAh/7/UqGobq6Glu2bFFXJQHAhg0bMH369Ijlo2SjlpEalT6dmWV2TAhkWg61OdX+l/xMi7pJJJt4iYiIguIKYGpqarBlyxYcOXIEe/bsQU1NDTZt2oQVK1agvr4eDzzwAHbt2oUjR47gb3/7G2644QYsWLAAVVVVAIAlS5ags7MTq1evxqeffoq9e/fim9/8JkwmEy699FIASh+NxWLBTTfdhL179+L555/H2rVrceeddyb+2Y+RmYEARqgszFSn9x5q7VVXIOVnWGCzKAEMm3iJiIiC4iohtbS04IYbbkBjYyOys7NRVVWF9evXY8mSJWhoaMDGjRvx+OOPw+l0oqKiAtdccw3uvvtu9evPOuss/P3vf8d9992H6upqGAwGnHPOOXjjjTfULE12djbefPNNrF69GvPmzUNBQQHuueeepF9CrRU6qXdqYQYqCzPx7udtqG91ojxXycbkZ1jVDMyAlz0wREREQlwBzJNPPhnxtoqKCmzevHnIx1iyZAmWLFkS9T5VVVV499134zm0pKLNwFiMBpTnpqNSk4GxBTaFzM8MLiVnCYmIiCiIeyGNgew0MybmpQMAJhekw2iQMLUwE4AyzE7sRJ2faVV3uOYkXiIioqC4VyFRYswqs+NYRx+mFiiBS6UIYNqcaOweAKDMgGkJrKfmZo5ERERBzMCMkaWzlOF8X5heCAAotlsxOV/JyoihdbPKspGmNvGyB4aIiEhgBmaMfOnsCfinaYUoCPS5SJKE175zibqdQF6GBeW56fjomLJ9AktIREREQQxgxogkSSjM0g/ey7CaUFWeo/ucaOhlEy8REVEQS0jjXLCJlyUkIiIigQHMOCcyMBxkR0REFMQAZpyzmZWXiAEMERFREAOYcS6NGRgiIqJBGMCMc1bRxMsAhoiISMUAZpwLZmDYxEtERCQwgBnn2ANDREQ0GAOYcY6rkIiIiAZjADPOiRKSxyfDF9gXiYiI6HTHAGacExkYgFkYIiIigQHMOGc1BV+iWFci+f0ynC7vqTokIiKiMccAZpwzGCQ1iIk1A3PrM7twwYMb0dbrOpWHRkRENGYYwCSBeBt5PzzWBafbh/qW3lN5WERERGOGAUwSCC6ljm0WTO+AUj7qY88MERGlKAYwSSCe7QS8Pr/aKzPgZgBDRESpiQFMErDFsZ2A0xW8D7cfICKiVMUAJgnY4thOoMflUf+/jxkYIiJKUQxgkkA82wn0apZPc24MERGlKgYwSSCeEpJo4AWYgSEiotRlGusDoKGJJl6XJoAZ8PjwweEOuL1+mE0GzJ+SB5vZiB5NBoY9MERElKoYwCSBcD0w//XGfvz+/SPqx1+/cCL+vy/N0WVg+pmBISKiFMUSUhIQPTDajMrekw4AQF6GBQBQ3+IEoO+BYQBDRESpigFMEgg3ibepewAA8PX5EwEAXf3K6iNdBoYlJCIiSlEMYJJAaBOvLMtqAHNWqR0A0N3nBgD2wBAR0WmBAUwSSAvpgelwuuH2+SFJwJnFmQAiZGBYQiIiohTFACYJiB4YsQqpMZB9Kci0ojDTBkBZMu3y+tCrGWTHDAwREaUqBjBJILSEJAKY0mwbsmwmSJJyv+5+D5t4iYjotMAAJgmENvE2dfcDAErsNhgMErLTzACA7j4PetjES0REpwEGMEkgdA6MNgMDADmBAKaLGRgiIjpNMIBJAjaTfg6MWIFUkp0GAMhOV2bBdPd5uIyaiIhOCwxgkkCaRV9CEhmYshxmYIiI6PTEACYJDOqBcQQyMHYlgBE9MF19bl0Gxu3zw+vzg4iIKNUwgEkCGRZly6rOPg/8fhmNgSbe0kAJKSfdHLjdjV63V/e1LCMREVEqYgCTBKYVZcJmNqC734MdRzrUZt4iuxVAsITU2DUAWdZ/LQMYIiJKRQxgkoDFZMD5k/MAAC9/eAIAkJ9hUUtLoon3eKeSmTEbpeD0XjdLSERElHoYwCSJ6sp8AMA/9jQCAEoCS6iBYAbmeGcfACDTakJ6oPG3z6MvKREREaUCBjBJ4qLKAgDBzRpLtQFMoAdGNPdm2kzqyiWuRCIiolTEACZJzC6zI9NqUj8uCRPA+AP9L5lWs1pCYg8MERGlIgYwScJkNGD+lDz1Y7ECCQCy0yy6+2ZZmYEhIqLUxgAmiYg+GCB8CUnItJmYgSEiopRmGvouNF5oAxhtCUkMshMyrSb4A+upmYEhIqJUxAxMEplRYkdZtg1mo4TKwkz182ajARmBkhHADAwREaU+ZmCSiMEg4ZmbL0R3vwfFdpvutpx0C5xuZQ5MltWkbjvADAwREaWiuDIw69atQ1VVFex2O+x2O6qrq/H666+rty9cuBCSJOn+rVq1atDjPPXUU6iqqoLNZkNRURFWr16tu3337t245JJLYLPZUFFRgYcffniYTy/1TCnIwNkVOYM+ry0jZVqDGZg+BjBERJSC4srAlJeX46GHHsIZZ5wBWZbxhz/8AVdffTU++ugjzJo1CwBw88034/7771e/Jj09XfcYjz76KH72s5/hkUcewfz58+F0OnHkyBH1dofDgaVLl2Lx4sV44oknsGfPHtx4443IycnBLbfcMoKnmtq0jbyZNhPS+vUbQBIREaWSuAKYq666Svfxgw8+iHXr1mHbtm1qAJOeno6SkpKwX9/Z2Ym7774bf//737Fo0SL181VVVer/P/PMM3C73fjd734Hi8WCWbNmoa6uDo8++igDmCh0AYxmEi97YIiIKBUNu4nX5/Phueeeg9PpRHV1tfr5Z555BgUFBZg9ezZqamrQ19en3rZhwwb4/X6cOHECM2bMQHl5Ob761a+ioaFBvU9tbS0WLFgAiyU422TZsmU4cOAAOjs7Ix6Py+WCw+HQ/TudaGfBZNlMsFlYQiIiotQVdxPvnj17UF1djYGBAWRmZuKVV17BzJkzAQDXX389Jk2ahLKyMuzevRt33XUXDhw4gJdffhkAcOjQIfj9fvz0pz/F2rVrkZ2djbvvvhtLlizB7t27YbFY0NTUhClTpui+Z3FxMQCgqakJubm5YY9rzZo1uO++++J9OilDn4ExI52rkIiIKIXFHcBMnz4ddXV16O7uxksvvYSVK1di8+bNmDlzpq7EM2fOHJSWlmLRokWor69HZWUl/H4/PB4Pfv7zn2Pp0qUAgD/96U8oKSnBO++8g2XLlg37idTU1ODOO+9UP3Y4HKioqBj24yWbnLSQHhiL2I2aAQwREaWeuAMYi8WCadOmAQDmzZuHHTt2YO3atfj1r3896L7z588HABw8eBCVlZUoLS0FADVjAwCFhYUoKCjAsWPHAAAlJSVobm7WPY74OFJvDQBYrVZYrdZ4n07KCO2BsXEVEhERpbARD7Lz+/1wuVxhb6urqwMANXC5+OKLAQAHDhxQ79PR0YG2tjZMmjQJAFBdXY0tW7bA4/Go99mwYQOmT58esXxEg3tg0i1KbMoSEhERpaK4Apiamhps2bIFR44cwZ49e1BTU4NNmzZhxYoVqK+vxwMPPIBdu3bhyJEj+Nvf/oYbbrgBCxYsUFcZnXnmmbj66qvx3e9+F1u3bsUnn3yClStX4qyzzsKll14KQOmjsVgsuOmmm7B37148//zzWLt2ra48RINFmgPDZdRERJSK4iohtbS04IYbbkBjYyOys7NRVVWF9evXY8mSJWhoaMDGjRvx+OOPw+l0oqKiAtdccw3uvvtu3WP88Y9/xB133IHly5fDYDDgC1/4At544w2YzcoJODs7G2+++SZWr16NefPmoaCgAPfccw+XUA9BlJAkCUi3GJFmUWJTlpCIiCgVSbIc2PUvxTgcDmRnZ6O7uxt2u32sD+eU63V5Ub3mLVTkpuMf370E+046cOXP30VhlhU7frR4rA+PiIgoJrGev7kXUorItJrw7g8uVZt3uQqJiIhSGQOYFJKTHmzkVfdC8vggyzIkSRqrwyIiIkq4Ea9CovFJZGB8fhkeX0pWCYmI6DTGACZFiQwMAPSzjERERCmGAUyKspgMMBmUslG4WTC/ePtzLHtsCxq7+0f70IiIiEaMAUwKS4uyH9JzOxpwoLkHf6w9OtqHRURENGIMYFJYcEdqr+7zXp8fjd0DAIA/7zoOr88/6sdGREQ0EgxgUli6Jfw03sbuAfj8SmNvS48Lmz9rHfVjIyIiGgkGMClMLSG59RmWhs4+3ccv7GwYtWMiIiJKBAYwKSy4I7W+hHS8Q2ncLc9NAwC89WkLWnvCb8hJREQ0HjGASWGihBTaxCsyMAvOLMTcihx4/TL+/vHJUT8+IiKi4WIAk8Ii7Uh9vFPJwFTkpuOiynwAg8tKRERE4xkDmBQWXIUUkoHpUIKVirw0WE3Kr4CHK5GIiCiJMIBJYemBDIzTpe+BEdmW8tx0mI2BAMbL7QaIiCh5MIBJYZPy0wEAe0861M8NeHxodigNuxW5abAEAhg3MzBERJREGMCksOpAf0vtoXb4A3NfTnQp/S/pFiPyMiwwG5XtBhjAEBFRMmEAk8KqynOQbjGiq8+D/U09APQNvJIkwSx6YLwMYIiIKHkwgElhZqMBF0zJAwBsrW8DoG/gFfcB2MRLRETJhQFMiqueGigj1bcD0DfwAtCsQmITLxERJQ8GMCnuosoCAMAHhzvg9fkHTeE1s4mXiIiSEAOYFDezzA67zYQelxefnHSoGZiKPCUDwxISERElI9NYHwCdWkaDhPlT87FhXzOe33EMR9sDAUyuCGACq5A0TbzNjgHsOd4NACjIsmJueTYkSRrlIyciIoqMAcxp4KJKJYD50wfBXafLA028lpAMjCzLuPoX76PJMaDe9083X6guySYiIhoPGMCcBv7lnAl4/2Ab2nrdAJRNHO02MwAEl1EHmnjdPr8avNhtJjgGvDjQ5GAAQ0RE4woDmNNATroFv115ftjb1CbeQAlJW0q6YnYpnt/ZgJYe16k/SCIiojiwifc0F1pC0gYwEwIrlVoZwBAR0TjDAOY0ZzEpzblqABP4r8kgocRuAwBmYIiIaNxhCek0F1xGHeiBCWRgLCYDCu1WAMzAEBGlimPtfXj3YCtkGciymbBsVglsZuNYH9awMIA5zUXqgbGYDCjMVAIYZmCIiFLDrc/swt6TDvXjH//zTNz0T1PG8IiGjyWk05x2Eq8sy3CJAMZoQFEgA9PhdMHn51YDRETJTJZlHGp1AgAqCzMAALuOdozlIY0IA5jTnGjiBQCvX1Z7YCwmA/IzrDBIgF8G2nuZhSEiSma9Li/6PT4AwA+vmAEAumxMsmEAc5ozm4ITdj0+v66EZDRIyGcZiYgoJYj38UyrCedPzgUAHG3vg2PAM5aHNWwMYE5zZk0GxuOVgwFM4PNFWWzkJSJKBeJ9vCjLipx0CybkKKMy9iVpFoYBzGnOZJAgtjlyazIw1sCE3sIskYEZCPv1RESUHEQGpiDwvj6zzA4gectIDGBOc5Ik6Xak1vbAAMzAEBGlCm0GBgBmqQFM95gd00gwgCG1XOT26ntgAKAoi8PsiIhSgciki/f1WWXZAFhCoiRmNgan8Yb2wKglJAcDGCKiZNYaeB8X7+uzJygZmM9bejHg8eFvH5/Exn3NMT3W8zuO4b6/78XBlp5Tc7Ax4CA70s2CcUUqIXEZNRFRUhPv4+J9vcRuQ16GBR1ONx56fT+e2noEFqMBH/9kKdIskafzyrKMJ987jM+aezG1MBPTirJG5fhDMQNDuu0EgiUk5ZeXTbxERKmhJSQDI0mS2gfz1NYjAJQL2cNtzqiP8/HxbnzW3AuryYAvzi07dQc8BAYwpGZbPGFWIYlaaWuPC7LMabxERGPh1d0n8acPjo3oMdQMTGDKOhBciaRV39ob9XFe2NkAALhidgmy08wjOqaRYABDar+LJ0wTr4jUBzx+9Li8Y3OARESnMVmW8b0XPsZ/vrIHXX3uYT2G2+tHh1P5WnFhCgDzJioD7cqybVg8owgA1O0Gwul3+/D3upMAgK+eVzGsY0kUBjCkTuN1+/xw+5Qx0yKoSbMYkWVVWqW4lJqIaPS5fX64vH7IMtAzMLwLyXan8v5tMkjI0WRNFs8oxmPXzsWLt16EcycpwcyhtsgZmNc/aUSPy4uKvDRcODV/WMeSKAxgSLcjdWgJCQAK7VyJREQ0VsT7MgC4vL5hPYa2/8VgCG4hYzBI+JdzyjEhJw2VhZkAopeQRPnoK/MqdI8zFhjAUIQm3uCvRhEbeYmIxow2gBnw+KPcMzIxy0u0BYQjdqg+3OoM2/PY3uvCtkPK7tXXzCsf1nEkEgMYCvbAaCfxavZIKtQ08hIR0egS78vA8DMwoVN4w5mYlwGjQYLT7UNzmIy7CF6mF2ep+yiNJQYwpA6yE3VWIHwGhgEMEdHo05WQhp2BUTLohZoG3lAWkwET89IBhC8j1R5qAwBUV45t74vAAIb0eyGFCWAKMhnAEBGNFV0JaYQZmGglJACYWqCUkQ6FCWC21rcDAC5iAEPjhToHJswyagDIz7AAADqHuXyPiIiGz5XAHphoJSQAqCwSjbz6pdTNjgEcanXCIAHzx3j1kRBXALNu3TpUVVXBbrfDbrejuroar7/+unr7woULIUmS7t+qVavCPlZ7ezvKy8shSRK6urp0t23atAnnnnsurFYrpk2bhqeeeiruJ0axs2ibeMP0wOSkK0vuOvs8o39wRESnuUT2wMSagQktIdUGsi+zyrLHdHidVlwBTHl5OR566CHs2rULO3fuxGWXXYarr74ae/fuVe9z8803o7GxUf338MMPh32sm266CVVVVYM+f/jwYSxfvhyXXnop6urqcPvtt+Nb3/oW1q9fH+dTo1hp90IKl4HJYwaGiGjMJGIVUixNvAAwNbCUOnSY3dZ6pf9lvJSPgDg3c7zqqqt0Hz/44INYt24dtm3bhlmzZgEA0tPTUVJSEvVx1q1bh66uLtxzzz26DA4APPHEE5gyZQp+9rOfAQBmzJiB9957D4899hiWLVsWz+FSjNRBdhHmwOQGAhgxxZGIiEaPvok3/gyMLMvBAMYeuYkXCC6lPtndj363T93UUfS/jJcGXmAEu1H7fD68+OKLcDqdqK6uVj//zDPP4Omnn0ZJSQmuuuoq/PjHP0Z6erp6+759+3D//fdj+/btOHTo0KDHra2txeLFi3WfW7ZsGW6//faox+NyueByBZtMHQ7HMJ/Z6UfbxBtuFVJuuhLA9Ax44fH51fsTEdGpp2/ijT8D093vUctQBZmWqPfNy7AgO82M7n4Prvz5uzAbJcgycLyzHyaDhPMn58X9/U+VuAOYPXv2oLq6GgMDA8jMzMQrr7yCmTNnAgCuv/56TJo0CWVlZdi9ezfuuusuHDhwAC+//DIAJci47rrr8Mgjj2DixIlhA5impiYUFxfrPldcXAyHw4H+/n6kpYVfe75mzRrcd9998T4dQsgcGBHAGINbqWenmSFJgCwDXX2eIWuoRESUOLoemGGUkLYdUrInZdk2WE3GqPeVJAnnT87Fxk9bBu1KfdG0AmRYh533SLi4j2T69Omoq6tDd3c3XnrpJaxcuRKbN2/GzJkzccstt6j3mzNnDkpLS7Fo0SLU19ejsrISNTU1mDFjBr7+9a8n9EkAQE1NDe688071Y4fDgYqKsd1oKlmYwzXxajIwxsDeGZ19HnT2uRnAEBGNopEuo35h53EAwBfPnhDT/f/nunNR19Clm8YrSRKqyrPj/t6nUtwBjMViwbRp0wAA8+bNw44dO7B27Vr8+te/HnTf+fPnAwAOHjyIyspKvP3229izZw9eeuklAFB/OAUFBfjRj36E++67DyUlJWhubtY9TnNzM+x2e8TsCwBYrVZYrTyxDocIViI18QJKGamzz8M+GCKiUTaSQXbNjgFsOtACAPjKebGN/0+zGMdVr0skI84F+f1+Xe+JVl1dHQCgtLQUAPDnP/8Z/f396u07duzAjTfeiHfffReVlZUAgOrqavzjH//QPc6GDRt0fTaUWNrNHNUemJA+l9wMC9DmHPZW7kRENDwu3/AzMC/tOg6/DJw/OVfdrDFVxBXA1NTU4IorrsDEiRPR09ODZ599Fps2bcL69etRX1+PZ599FldeeSXy8/Oxe/du3HHHHViwYIG6XFoEKUJbm7Isa8aMGcjJyQEArFq1Cr/4xS/wgx/8ADfeeCPefvttvPDCC3jttdcS8HQpHLGVgNIDo/xxhMvAAECHk7NgiIhGk34ZdewBjCzLeFHsHn1e6rVUxBXAtLS04IYbbkBjYyOys7NRVVWF9evXY8mSJWhoaMDGjRvx+OOPw+l0oqKiAtdccw3uvvvuuA5oypQpeO2113DHHXdg7dq1KC8vx29/+1suoT6F1Em8ms0crYMCGDHMjhkYIqLRpCshxbEKaefRThxp70OGxYjlc0pPxaGNqbgCmCeffDLibRUVFdi8eXNc33zhwoVht+xeuHAhPvroo7gei4YvWEKSI/bAqMPs2ANDRDSqhjsH5pMT3QCAfzpjfK0eShQO9CA1gBnw+OAPxJNhe2AAdDADQ0Q0qty+YNASTwamu18p+edlpOYCFwYwpPbA9Lq86ucG98AESkjMwBCljA8Od+DCn76FNz5pGutDoSiG2wPj6Ffe08fL3kWJxgCG1H4XZ9QARuyHxCZeolTx1qfNaHIM4J39LWN9KBTFcHtgHAPK+7U9LfXKR0ACllFT8hMlJBHASBJgMki6++RG2dDR5fXB7wcMBgw55ZGIxo+WwP442kmvIyX6GiVJGuKeFCvt6xNPBkaUkFI1A8MAhtQApicQwFiMhkFvPsFl1PoA5vGNn+EXbx+E1y/DIAE/uWoWVl40+dQfNBGNmNjgzz2M/XXC8fj8+OIv3kdhlhV/vPGChDwm6bMucWVgAgGM3ZaaAQxLSDQoAxNaPgKCq5DEho4A8NruRjy+8XN4A52/fhl49/PW0ThkIkqAlp4BAEoWNRFOdvXj00YHtnzWCp9/8ApTGp5h98AMKO/p9hTNwDCAIVhMSrZFvN+EzoABghs6AsqGjvWtvfjBSx8DAL69YCr+65o5AICBYWw0RkRjQ5SQ4rmqj6ZL0yPndHuj3DMxZFlGa48LrT0uXQ/feOL1+eEfYTA37B4YlpAo1ZlDlkyHLqEGlA0ds9PM6Aps6Pj9Fz+G0+3D/Cl5+P6y6dj4qbJ/VX8cVwdENHZcXp8acCQsgOkPBjB9Lt8pL12senoX1u9V3nvMRgn/d9N8XDh1/OzhM+DxYfGjmzExLx3P3nzhsB9nuD0wwRJSap7qmYGhwQFMmAwMAOQF+mA+OdGNj493w2iQ8PPrzoHJaIDVrDTvxvPHRURjp6032M+WqACmu390MzDbDnWo/+/xydh5pCPKvUffsY4+HO/sx/bDHWGHtsZKu4HjgMcf02P5/LLa18gSEqWs0IAlUgCTE5gF8489ysyIOROyUWy3AQDSGMAQJRXRwAskrom3W7NKMZaSjizLuvlT8RLvN2JMvuj5GC/EogefX4bHN/wAJnSVWCyrxnoGgsEkm3gpZYWWjCJmYAKNvFs+Uxp1L9Jst25TAxj2wBAlgxbHgPr/iWri1fXAuIZ+zHv+uhfn3r8BB1t64v5esiyrmaPCLGXSbPc4m1PVpQno+t3D/xmHBpixvM+KIXZpZmPE9/Rkl5rPiuISSw8MEFxKLaL/al0AE9yOgIjGv5ZTkIHR9cDEUEL6qKETbp8f+xrjD2C0Za8iuxLAOAbGVwDT4Qwez0j6A0Nfn1gCzlSfAQOwiZcQ3EpAiBSti2F24mvOm5SnfswSElFy0ZaQTs0qpKHfC/oCWZr+YfTLaN9rirKUUvZ4C2C0gz9HFMCElIxET8yx9r5Bz3lCThpyMywpP4UXYABDAMyDemDCT9MVGRgAOKciF2mW4P1ECanf44Msy5zCSTTOnYoMTHd/fD0wotG3bxjlFVFGMRok5AcurrRNxOOBdu+4WDJSkYTLwLzxSRNWPb1r0H0zrSa8f9dlKT/EDmAAQxhcMgo3BwYA8jKCfwja8hEA2AJBj19WVgOI2TJEND7pMzCnogcmhgAmkIEZXgCjfI3NZFBX2Yi+j/GiQ5OBGUl2OjRDNuDxY9/JbgBAhsWoPv/WHhd6XV583tJzWpSQ2ANDMS+jztFkYC4KDWAswa8ZSNCbIRGdOq092ibe2JbmDkXfAxP9fUCWZTUDM5wGV/E+YzMbkR0ok4y7EpJT28Q7/CyXO+Q91eX1qQHKNy+egtqaRaitWYRzJ+UCABq7BzQlJAYwlMKMBglGzeaN1ghNvCJNazUZcPbEHN1tyv5Jyv8PjKDbnohGh7aEJMtQtwQZiXgyMMo8E+X/R1JCspmNapnE0e8Z8dTbROrsi6+pORLRA5NhCa72FEvGtRmW0mylF6ipe0DNRqVyBoYlJAKgNOWKvUsiZWDmlGdjycxinD85d9Cu05IkIc1sRJ/bx6XUROOc3y+jrdel+5zL6x+UjY2HLMv6HpghTtja2/s9w2/itZqDJSS/rDxu1jjp+0hYE2+ghGRPM8Pp9mHAE8zAaJt0SwIBTGP3gLpnXapO4QUYwFCA2WhQA49IAYzVZMT/3nBexMewBQIYbidAlFj1rb2w28zqvJOR6ur3DBqs5vb6gRE8fL/Hp3vMviHmwGgzNMMqIak9MEbYArNO3F4/uvs94yaA6XCOvAfG6/Or+9Rl2Uxo7FaCzXD7HJXaRQDTr76Ps4REKU/byBtpDsxQbCbOgiFKtJaeAVyx9l187Te1CXtM0cCbm25WxyiMtJG3K2SI3FATdrWD7kZWQlLed7LHWSOvx+dHj2Yy8HCeI6BfQi1KZQMeX7DHRROslWSnAQj0wPSzB4ZOE9rU8XCnNtosnAVDlGgfHu2C2+tHfaszYX9bLYEG3qIsm3rBMtKl1KEBzFAn7D5dCSn+5+XSNPECwVLJeGnkDf15DDczrX1dsgLP0RXINAH6AEXbA9PNZdR0ujBrlj0PO4AxBWfBaPW5vdjyWStcXj+MBgmXTCtEdnrsf1SdTjc+a+7BBVPyOF+GUs6HxzrR0NEHAJhWlIlZZdm628VyWQBocbgwMT89psf1+vzY/Fkrel1eSJKEiyvzkZ9pVR8HUCbYtva64HT7Yhpm98mJbuRmWDAhJ23QbV2a/hdg6B4YbYZmONkJl6aJFwieyMfLLBht/wswuEwmyzJ2Hu3E9JKsqEGGCGAMEpBuVU7ZAx5f2CZdEcC09Ayoc7rYxEspLyEZGHU7Af0b4SPrD+D37x9RP15eVYpfXn9uzI9715934819zXj2W/Nx0bSCYR0b0Xh0uM2JL/9qq/qx2ShhW80iNdAAgL0nHer/N3b3xxTAyLKM2579CG/sbVI/t3B6IZ765gUAgNZAA29hplXNwLiGaL5vcQzg6l++j0l56Xj7PxYOuj10H6KhemC0QcuwSkhqBia0hDROAhhn9ABm19FOfOWJWlQWZuCvt/0TMq3hT8cisLSYDOpFYu+AV71Q1AY/+ZlWmAwSvH4ZxwJBcSpP4mUJiQAkpgdGRPyhtfR39rcAAKYWZAAADjTFvu+JLMv44EgHAOBga++wjotovPq0UQlOstPMSDMb4fHJOBo48QifaDIwTZoNGKP533cP4Y29TbAYDZhbkQNAaQQWRAam0G6FNRAAuH3Rg4jjXf3w+WUcanOGLdOIGTAFgeBr6B4YbRPv8FchiZO6OJGP2wxMSGb6SLvyOte3OvHDP++OOIdH9MBYjAb1tRJL4CUpWFYClJEYxYFGXrGqNJVLSAxgCIA+6xJpEu9Q1BKS5krjZFc/jrT3wSABj157NgClPhurE139ai1ZvOkSJav2Xhfe3t+snqxE6egLZxZiekkWAP3veVuvC82aj092Df23s/1QO/7rjQMAgHuumom1gb+79t7gCXU4GRhtZuNQq3PQ7eLvdEKuUl4aau6Jc4QlJJHptZr1pRLHwPho4tVu5AgMzsD0aoLAV3c34g9bj4R9HLeagTGq77GiCTvTaoLBoC+ri6XUQjzl+mTDAIYAnLom3tr6dgDAnPIcnFGUCUC5MuuJsdFOmz7Xjj4nSjaOAQ+uWbcVNz61E5s/awUANHQqAUxFXhqKAkukWzXzWbS//wDQ1N0/5Pf56ev74fPL+NLZZVgxfyLyM5UBlH1unxpUtAQyOUV2m3pV7/JFD2C0mY36lsHZUNEDUxY4gQ61maP29hEtozaL5cKBJt4kycCIDFVeYEDoQ2/sD9ukLQIYq8mgPlfRhB0uu6INYCQJyLSwhEQpTrsj9cibeINvhFsDAUz11HxkWE3qSoFYszDaN/CWntgzN0TjiSzL+I8XPlbLBnuOK2Whhg4lIKnITVdnvLRqykR7A+Uj0bveOMTfjd8v40CT8jfz3cVnQpIkZFpN6t+0yMKIi4GiLKs6lHLIDIwms3GobXAAI3pgygINvm6vXx2mFo42Q9MX2AQ2HgOhTby28dkDUxAIIEMDmJ5AAPMv50xAls2EAY8fR9v15UNAU0IyGdTXSmTlwjXoilkwAJAVJkOTShjAEICQDIwx/G7UQwk28Sp/qLIsY9shJYAReyeVauYUaPW7ffjzruODrsS0KzBae5mBodG1+bNWfHKie+g7hiHLMv5adwK/3lyPH/55D97c16zedqhNKcEcVzMw6SjKEitIBmdg5k1U9rgZqgfmZHc/Bjx+mI0SKgKlHEmSUBC4ym936gOYwqxgCck9RAYm1hJSmWaFUrRGXu0cGJ9fHvL7h1KbeE2hJaTxEcCIjRzFzyO0TNYbCAizbCZMLVSy04fC9PmpJSRjMAMj3gvDNehqMzCpXD4CGMBQgCUBJaS0wJWQeGM51tGHE139MBslnDdZeQMuzQnOKdBa8/qn+N6LH+O/3tiv+7wuA8MeGBpFrT0ufOP3H+CbT+0Y1kaH7x1sw3efq8Oa1/fj+Z0NAJSVQIDSUCvLMo53KhmY8tw0FNmt6vcV9gaCp8UziwEMnYGpDwQWk/IzYNL8TYtVTe29LvS7ferVf1FWsInXNcScEm0AUx/mRCtKTNqgKNpS6tC9kuItIw0uIY2vJl41oAtctIWWh0QJKdNqQmVggUO4n6vbq83A6Gf2hMvAaAPIVG7gBRjAUEBillEHApjAG5Hofzm7IgfpgTpsqWavDqHf7cMrH54AALz84XH1D72916W7X1uvS+2sJzrV2npdkGUloBjOSXFLoM9lenEWrjm3HP91zRz855UzACgZjNYeF1xePwySctIpFDNaAgFMz4BHLTktnlGkHlO0gXPiCr6yMEP3edEH0+50qwGSzWxQykuiiXeIOTDazMaR9r5Bf4tiFVJOmhnpVuW9IFojb2hGIt5GXlHyEif18TaJV2wjIAKKwU28wQxMZZHIwAzObOmWUZv12fGhemBSeQYMwACGAswmbQkpMXNg1P6XyuDslhK78sfc5Ag2I76xt1G9InQMeLE+MLtCZF8q8tIgScpGbR0hsxWIThVtz4LoVYlHbaB8+u+XVuJnX52La8+fiEn56TBIytX3rqOdAJSyqtloUDMwotfr00Zl3EBZtg2VhZmwGA2Q5ei9YOIKXpQkBNEo2t7r1k3hlSRJXcUz1CRebRDn9vpxolP/M+kOlExy0s3ICFyw9EYrIYUEN/FOqg1mYEJ6YMZJCalTLSEpAUVogNajZmDM6oiJ+rbBAUy4ZdRCuG0CSjUBDDMwdFpIRAnJFlJCqmvoAgBcOCVPvU+4DMwLO44DgLoK48WdyscigKkqz0F+4A2Yjbw0WgY0JxyxWihWXX1u9fe3emq++nmryYiKPGUQnViJVB7oVRFNvG29bvj9sjojZmaZHZIkqVfW0RrgxRW8OCEKBZoSUoum/wVA7BmYkMxGaLmjS7O5YIbIwESZBTPiElLoVgKBfpDxUkLqDMnADCohBTIwmdoemJbeQeVKd5hBdkK4DEthphWibzeVh9gBDGAowKLZSmDYc2DM+jkw4g9Ym9IMfRM+2u5E7aF2SBLwi8B03vfr29DQ0aeuwJhVZkdhoMGRS6lptGivmBs64gtgth3qgCwrWwMUaVaFAEBl4GQlAhgR0BRkWiFJSkNrR59bDRCmFSnzYUrCBP+hRAAjShJCfsbgEpK4YFAH2cVYQkoPjEvQBjAur0/9eeWkWdSScbSl1E7XyEpIkTZz7HP7oq5+Gg0en19dtRWxiVfTAyMycz0u76DFCu6oJaTBAYrJaFAbwllCotNCInpggk28fvj8spoiDbdXx8kuJf380i4l23LJGYW4YEoeLp6WD1kGfvjybnUF06yybPVqsYUBDI0SXQkpzgyM+N3VZl8EkR0RgYjIwJiNBuSlK4FGa48rGIwE+lmC2cvw5axel1ddpVRZEBLAZIrsjktTQgoEMCaRgYkeQIjMxtzyHADBlVTa28RkWDEWPzTLohXaHzPU4LtQIqMhSmBZmnJJzxgPsxMNvJIUfN36Q5aKi1lYWTYTbGYjynOVQLa+RV9GcgdeF20TrxBplZEIdllCotOCOQFbCaglJI9PN6hOW6cVf1iOAS+cLi9e3d0IAPjKvHIAwLXnTwQAvH+wHW29bhgNEmaX2YNDvhjA0CgZSQ/M1vo2AMHxAVqh/SkVucG9jbSBemg/y1AZmMOBgKcg0zLoxKY28fa6dUuogeAFy5AZmECQcvbEHAD6YXZiBkx2mhkGg6RmaaKtQhL9MSLYGfYqpEBZxWiQkGUdH2WkrkD/i1JOC2ZJRJlOlmVdBgYApgYC1dAZO6IHxmo0qMGaEClAmRIIkotDpvKmmtQukFHMEruZY3Cn1HSLUffYWTYzMq0m9Lq8+OhYFw63OWGQgC8Elpf+85xSdPW50Ry4kjy7Ihf5mVYGMDTqtCfU43FkYFp7XPisWTkJXRgmAxO6QkiUkAAlqNjf1IOj7U41UFEzMPboPTDixDc1JPsCAAUZgR4YZ7AHRpQZ1EF2UQIYWZbVksg5gb2VtBkY7QokAOpJO9ocGJFxKcyyotfljX8VkldfQgKUi6Uel3fMh9mJxQZ56RY1Mw0oZSSb2QiX1w+PT8nGZAbKQJWFmdh0oHXQSqRwy6iFcE28APAfy6bjnIk5uKqqLDFPaJxiAEMAAEsCJvGmaTIw4goo0jK/gy29ePkjpXw0pzxHvZ/BIOGG6smDviZ4ZcomXhod2gzM8c5+yLIMSRp6qqkoH80otSM30HuiNSgDkxec2yF+z7cfVjYwzc+wICdQViqJMARSEBmRqSEBEhDMwHQ43cGNHENKSKEZmE8bHXhtdyNuXVgJGcHNAUUGprXHhe+98DEMUnDAXnbgWEUTb6QNHf1+WQ1YCjItONzmRF/cq5D0k3iB4MaGY52BESuQcjMsMBokWEwGuL1+9XdK+3MRK7bE6xbaHB2tByZSj8uEnLSw76OphgEMAUhMBkakN/s9PrXhL1wXfGkggHnjE2W5dLg0e6giNvHSKNNmYFxeP1p7XIMacsMR4wMi/V4XZFpgt5ngGPDCbJRQnBV8TPF7vj0QBGmDkbIIQyAFsQS3snBwBkYso/b4ZBwO3C80gAntgVm78XO8sbcJE/PS8U9nKKMQzEYJhZlWTMxLx7GOPvz5w+O6r5kQOEZxUo7U16INDsUKqXh3pHaFLKMGxs80XlFyFNsIpJmNSgAT+J1SVyBZTTAGlgyJzFloBsalXUYdmoFJ8R6XoTCAIQD6oGW4PTDBDIxfTeGG3asjWz8XIVyjY6jgjAwGMDQ6QueSNHT2xRTARGvgBZTR/lMLM1HX0IUJOWm6vWqKNEupAX05SPTAtPQMwOvz6ybtApol1GEyMDazUS3diuc1uIlXn4ERo/AbOvvUjEZ2mhmSJOHX/zYPmw60QkawKdVsMGB5VSkADLkKSTT3GiSoWaq4VyGpy6j1JSRg7IfZid+BeZOUCeRpZiO6+z3BACak/wUAKouU1+14Zx8GPD41MBtOBuZ0wQCGACSqiTfYAxO9hBRMmWu3GYhGTCk91RmYo+1O/O69w7h5wVR1VQCdnkKbShs6+jFvUvSvaezuV/u6LpiaF/F+lYEARtv/AgSzIur9ioLBSEGGFSaDBK9fxqqnd6Eg04o7l56Joiwb/H4Zh9t61ccOJz/Top44DVJwZVKkJl6RJWjsHlAvSMTf84xSO2aU2iM+v6HmwIjAJsNiQnrI+IVY+Pyy2kOinY2SPQ62E/D6/PggUAKsnqpkrkRTswgeezQzYITCTCuyrCb0uLw42t6H6SXK8nl9ABN8bzYbJd3Hp6PT+9mTSkziNRulYe9eql2FJFK40TIwgH6bgWjEG3uf2xexrp4If6w9ij/UHsUz24+dsu9BySE0IxBLI6/YPkPb1xXO7AnKyX96cZbu80UhAYw2A2MwSGpwsvHTFjy3o0Ed+tjcM4ABjx8mg6Quyw6Vr+nHyc+0qqWLSE28PS7lb7ixu19t4M2K8YpfNPFGmsQrMjAZVpN6co8nA6MdCqfNSoyHabyfnHSgx+WF3WbCzDLldbaZ9QFMuAyMJEmYEsieHW0PlpH0Tbz65xpLT1YqYwaGAASbeIebfQGCJSSPT0aHU/TARN+rQ7vNQDQZVhMyLEY43T60OAaQGeEqc6REhocbR5I4SeZnWNDudMe0lFrdPmOIsuh1F0xEabYNF03T//6HZmBCy0G//rd5ePdgGzYfaMHGT1twIjBPSTT2Ftttg0pLgsi4AMGMJhBbBqY7Skk4nGBQEiEDEziBp1uNSFP7ZYYXwGj7QsbDNF6xhP7CqflqkJgmMjCBn0evKzgDRkvpgerWlcq1WwmYjRIMgW1VTvfyEcAAhgJECWm4DbyA/kpIrBYKNylSm4GJpYFXKLLbcLhN2QQvdCVHoojVA+1OBjCnO3G1PK0oE+2HO4YcZifLspqBGer32mY24vLZpYM+r+2xMRulQSWmyQUZmFyQAbNBwsZPW9AYCGBEY29JlLkfoqFU+T7BACZcE692TkmTJoAJ9/ccjjrILkJQ0qcpIaUFyiD9nuiZ1RbHAP7rjQO4oXoSCjQzbLQZ4+CGjqc+gPH7ZTzw2j4cDKz+mllmx51LzlR/B6o1vwOhJSRtE69WYZhxEdpNKyVJgtVkRL/HF3M2LJUxgCEAiQlgtFdCIoMRLgNTkZsOu80Ei8mAswMzJWJRmGXF4TbnKW3kFfMb2nu5aeTpTmQPppdkYXsMAUxDRz9OdPXH3NcVTmagpNLn9mFiXrquN00rdKid+G9plAAmPyN6BkZbQtLOKelz+9SNG2PPwESfxCsG3GVYjep9h+qB+fOHJ/DnD4/D7fPj9sVnAABsIe9XIssU79YPw7Gv0YHfv39E/fjdz9vg6Pdi5xFlk86LNNllcXEnAreeMCUkIFhCDJuBCTxXm9mAfo+PGRiwB4YCEhHAGAySGsSIQXThApgMqwl/WX0xXr714kFd9dGEuzpJNDECvL2XGZjTXX/gyveMQJ/KyS5l9U8konQQa19XJOL3PFqWsTRb7Oqu/J01BbYXiBbA5GVEysAM3o06tM/sQLOysWSkwWmhhmziFT0wFpNaXhmqhHSsQ+kLae91DdqJWjgvsOpnz4nuU94HI94ryrJtuOvyswAAf/rgGPo9PuRnWHBmcfD1UzMwocuoQ0tI9sHvcdoeGCD4esWaDUtlDGAIQDB7MpIeGCD4hiICmEhXCVMLMzExP75VPuGuTmLx9Laj+I8XP4568hFEBqbN6R60KyydXsRu1JPz02ExGuDzy1E3UqwVy6dj7OuKRPyeR1pNBAQzMF19ytLcRrWEFL6BFwgOs1O+RzDQCbeMujdkL6EDTT0AYp87kjFECUls5JiuaeINXbYeSvQgdfZ5wg6xA5SNEyfnp8MvAx8c6ojpWIdLBEgTctNw68JKrL60Ur3twsp8XYOtdsgnEAwQs0JLSOpqy+DvmRrAGJXHECuPYg0mUxkDGAIQ3FAutOYeL/GHKlYtJHLQ0sTAse08Evsbk98v46HX9+OlXcdR19AV9b79bp/6Jur2+qPupEupr88jtsMwqX8fx6KUJvadVLIUYvbHcInls+cEJt6GY7cFT/xNjgG1ByZaBqZA28SbFb2EFJqBEXNpYi1bDDXITnw+02qMOQMjSnidTrdmiN3gU5gIIEVAeaqEjoq4c8l0XDxN6XtZMqNYd99BJaSIGRgx60fTAzOohKQ8FktIDGAo4IziLLxx+yX4+XXnjOhxQt9Qwk3iHa4r55TCIAE7j3YOGrcdydGOPvXNONrJBwg28AosI53e+t3KiSPdYgxutBfl9649kL0riWHYXTQ/unIm/rL6YiydWRzxPpIk6XanboyhiVefgYnexBtpN+dY/57TrcEVieF2uRYXB+kWU0w9MD6/rO5g39HnVofYaZcVC6KBWqwIO1VCh3UaDRJ+/40L8Mq/X4Srz9bvQRRxDoxVH4QEBxm64A9s3TC4hBTIwJzmU3iBOAOYdevWoaqqCna7HXa7HdXV1Xj99dfV2xcuXAhJknT/Vq1apd7+8ccf47rrrkNFRQXS0tIwY8YMrF27dtD32bRpE84991xYrVZMmzYNTz311PCfIcXsrBL7iP8oTuWkyGK7DQunFwGAOv9iKHtPdqv/f7wz+jLY0ACmjY28SeHFnQ345u8/SPh8IJHuTzMb1X6U+pAx74LX51d/f/LC7H8UjzSLEWdX5Aw540P0wZzsGlBLtjE38YbJwETrgRHizcAAwDv7W/DlX72PpY9txuWPb8ELOxs0PTDGIZdcA0pJWjQVu71+dUxDuAyM2EDz00YHOp3x/Q3vPt6Fq38ZPNZnth+NeF81A6P5mVhMBpwzMXfQaze4hKR8bWgGRmTJPD5Z3SDTHQjWRHlfbNmSyIvDZBVXAFNeXo6HHnoIu3btws6dO3HZZZfh6quvxt69e9X73HzzzWhsbFT/Pfzww+ptu3btQlFREZ5++mns3bsXP/rRj1BTU4Nf/OIX6n0OHz6M5cuX49JLL0VdXR1uv/12fOtb38L69esT8HTpVAsNYBJdp/3qeRUAgD9/eDymnpZPTjjU/x9qZUKnU9/0xwxMcvjtu4fxzoFWvPtZa8IeU5Zl9YSaZjGqO0JHyvx19nkgy4AkAbnpo3NlLLItn5zohtcvwyDpVxeFysuwoNhuRV6GRZep0Q6yE31f4gQbKtYLHKMhOCX2O8/V4cNjXfisuRf7m3rw2IbP1AAp3WpST+7RSkihf7ti+Xi4RQCFWVa1gXZbnGWkxzd+jo8bgsf6y7cPRrxvcL+3oX8moWWySD0wFpNB/f0Rjbyhq5CmFii/i2eGDEE8HcUVwl111VW6jx988EGsW7cO27Ztw6xZswAA6enpKCkpCfv1N954o+7jqVOnora2Fi+//DJuu+02AMATTzyBKVOm4Gc/+xkAYMaMGXjvvffw2GOPYdmyZfEcLo0B7RWRJAGZI1iNEc5lZxUhP8OC1h4XNh1oxeIoaXZAn4EZahlsR2gJKc6rNxobbYFAM1qDbbzcPj8CGXykWYIZmNCN9gQxNyg33RJxkFyiiWzLR8eUZbtFWZGH2AFKUPGP71wCnyzrSi/alYcenwyLSVKbeLNsJl05KZ4LkgyLCQMeN9xeP86uyMH3lp6Jm57aicbuAbVfSDuJ1+X1w+eX1eFvWg0h2dOTgdc6XAkJUJYwf9bci6317bhizuB5O+E0Owaw6UALAOChL8/BD1/egybHANxef9jVmWK/pVhWA6XFuAoJUAKwzj4PWnoGML0kS82MidLR/VfPxre/UIkpBYP3vDrdDPsvzefz4bnnnoPT6UR1dbX6+WeeeQYFBQWYPXs2ampq0NcX/aTR3d2NvLzgniG1tbVYvHix7j7Lli1DbW1t1MdxuVxwOBy6fzT6Qsd6D3dbgkgsJgP+5ZwJAIA7nq/DxQ+9rf67cu27ONIWPMHIsqy+UQIYcpJqV5L0wDy7/Rj+dd1WdcVUn9uL636zDb9991BMX//Yhs90P7NY+4nGI59fVks3YklxIgy4g9m9NLNRveo90dUftldDzA3KH2H5KB4ii7I38Dserf9FyM+06lYgAfr5TaJfRcwpOaNIvxIqnpKwWImUl2HBr1aci0vOKFQbk/cHVjUpJaTgSby914Vrf12r/n7e8sed8Pr8gzIwYtl4pL2ARBlJLG2PxZ8/PA6/DJw/ORfXnl8Bm9kAv6z0GIUTroQUSVqErQRCJ/ECwRViagYmpAfGYjIweAmIO4DZs2cPMjMzYbVasWrVKrzyyiuYOXMmAOD666/H008/jXfeeQc1NTX4v//7P3z961+P+Fhbt27F888/j1tuuUX9XFNTE4qL9VfVxcXFcDgc6O+PfAJas2YNsrOz1X8VFRXxPjVKgDRtAHOKarTXzZ8Ii9GAHpcXJ7r61X/7Gh14cVeDer9mh0uXRWns7ocnStmpw5kcPTBPvncIO492qleL2w61o/ZQO/5vW+R6vdZTW4/ofmZv7m0+lYd7SnX1udVMSSIzMGIFktkowWw0IC/Dop68D7cNzsKILJC2UfZUExkYb+AHEK3/JRptACNOliJDMC0kgAl3wo1kZqkdFqMBj197NspylH6di0KWmKdbTLCZDRAtI+v3NmH74Q719/PNfc34qKFrUP+aeK0jzZE6PzBIsL7VGbW3RpBlWe2r+8p5FZAkSd3MNdKFT7T93kKlhWxY2RNhEi8weFxEcBk119yEivsMM336dNTV1aG7uxsvvfQSVq5cic2bN2PmzJm6QGTOnDkoLS3FokWLUF9fj8rKSt3jfPLJJ7j66qvxk5/8BEuXLh3xE6mpqcGdd96pfuxwOBjEjAHtG8qpWuZXWZiJd++6VG1cBIDNB1rxsw2fqWO8gWD56MziTBxp74Pb60dT90DEpeKi4S/NrIzqDg1oxgOPz4+j7crVqHhjFf91Rtg4L5R4Q7/kjAK8+3kbuvrH3/OMlTZAbYpwpTwc4kQjfp8lSUJlYQY+PNaFQ2296iZ96nGIDEyUHpREK7HrZ77EkoEJR5IkWIwGuH1+dSm1yBCU2G1qGSndYow4GTic/7n+HHT3e3TLt6sr8/HYxuB9Mq0mSJKENLMyffiDwBTby2eVYMDrw6YDraitb1fLv2I37mAAE3nfp7wMCzqcbhxqdWL2hOyox7rjSCcOtzmRYTFieaDkVJ6bhoMtvRFLz6HLqKNJ06xCcnuDP+cs6+CvFQ3WYpp5aA8MBcX9E7FYLJg2bRrmzZuHNWvWYO7cuWFXEgHA/PnzAQAHD+obofbt24dFixbhlltuwd133627raSkBM3N+ivC5uZm2O12pKVFHtJktVrV1VHiH42+cDvDngrFdhuqynPUf18KlJU+Pt6tvvmKBt7ZZdnqHI9ojbydgcma4qpzPO6H1NDRp15xizdW8Zz6Y7jSdGtGxIudkLv7xm7ju5Fq05T54snADHh8uP5/t+G/3tgf9nbRbKnNKKorkVoGZ2BEsFswiiWk0IxLWZQhdkMJHWan7dEQ3yfeCxKz0aALXgBlSrE26BDLrUUfjJjxdNG0fCwKzFLZWt+G44HfcTEjRwQPtgg9MECw2fVQmIxZqBd3Kpnbf64qU0tfFYEMTKRdyEUPTLwZGO32CmJisZY6cTywlFr8vTKAGWzEPxG/3w+XK/wbfV1dHQCgtDTYRLV3715ceumlWLlyJR588MFBX1NdXY233npL97kNGzbo+mxo/NK+OY3mnIKKvHRU5KXB55ex47DyJigyMDPL7OqbUbRGXtFLIer+43E/JG0TqXhjFc+pz+Mbcnqwtn+jNJDWH8ude0dK+xo1OwbU2RlD2X28G1vr2/HE5np1R2ctsdxVnFiB4M7Qh9oG9wyJYDcvY/QyMDnpZt3f23AzMMDgpdTBvXrM6nLtRPw9W0wGnD852PMolluLDIUIQmeV2dV5Lh8e7VL7m6rK9ZmUaFuRiNervmXoHi8x5PLyOcEFKBV54qInegkpllK5NgMjLrDSzMawTdfqMDvHgJp9AfSlPlLE9ROpqanBli1bcOTIEezZswc1NTXYtGkTVqxYgfr6ejzwwAPYtWsXjhw5gr/97W+44YYbsGDBAlRVVQFQykaXXnopli5dijvvvBNNTU1oampCa2tw+eOqVatw6NAh/OAHP8D+/fvxq1/9Ci+88ALuuOOOxD5zOiVGo4QUyUVT9RM4RXPj7AnZQ74ZAcGr6MpAADMee2C0DbehJSRZhjpiPRJtb4fYnbgriTMw2kZrj09GW4xZM/FayzLwUpiZQv1h9tqpVGfBDD4htqklpNHLwCjD7IJZl+H2wACDh9klIgMTiXaXZpGBSDcHgwBJUmZSTS3IQLHdqq4Is5kNOKNIv3Q4UgkJCL5esWRgxCTjiZrycrSLnoFAKQiIrYlXO8gu0hReQd1OoNelC2CYgRksrh6YlpYW3HDDDWhsbER2djaqqqqwfv16LFmyBA0NDdi4cSMef/xxOJ1OVFRU4JprrtGViF566SW0trbi6aefxtNPP61+ftKkSThy5AgAYMqUKXjttddwxx13YO3atSgvL8dvf/tbLqFOEqPRxBtJdWU+nt/ZgK31bWjs7levrGeW2dUrrEjpYCB4IhclpA6nksJN9EqqkdBmYERTsvYN1un2qld74ah70FhMyEkPBDDjOAPz4Gv78Pv3j0CbVzFKEu5ceiZWfaFy0FL3pu6BQatswtGuOHtxVwP+32XTdK+zWkKyaAMY5Yr+cKsTsizrhpWJQKpgFAMYQOlREU3FiczAaOeUiMdN1N+z0sh7AMDgDAyglH5EGad6aj7+UncSAFCemz5oSGD0DIxY+h49A9Mz4FEzTtopyqJXLtxFj5jCa4hxVIR2K4FIM2AEdUNHh0s3XJBNvIPF9Rv55JNPRrytoqICmzdvjvr19957L+69994hv8/ChQvx0UcfxXNoNE5or4hGOwMjruz2nnTg1qc/BKDsJ2O3mTVXUzFkYAJvfH5ZObmPdLJqImnLF35Z2WRPO6ejz+UDIu8BqDbwZliMyAm8Pt194y/TJPz940a150fwQcZfPjoRNoBp7B5AVfnQj6ud+XO8sx+1h9px8bTgCplwJaSJeRkwGiQ43T40O1y6gEEcx2g28QLBrIskIabALRLtMDsgGMBk2kyonpqPXxnr1aXJIzW7zI4zizMhy8H3CO3PeVZZsEx0UWWBGsBU5KYhN+Rv0RpDCelQqzPqhYhYDGC3mdTACQjuD9cW2P1aGyyJ8lFWjKMixIWd2+tXS7YRMzCBHpgel1cNlCxGw5CTmU9HnEVMCaVr4h3lAKbYbkNlYQbqW52oa+hCptWEn31lLgBtPTt8BmbAE9zIschuRXaaGd39HrT3usZVACNG2YvVGLUh+72IElEk2sxCTmDi53jOwIg3+5f//SKU56ThWEcf/vWJWjR09EGW5UGzeppibOQVK84kSSkj/emDYzh3Yi5MgWXT/WGaeC0mAybmpeNwmxOfNjoCPSjK7WMxBwYIZl0KMq0jKjFYzSE9MIETdKbVhBmlduy5b2nEoXHxMhkNeOO7C+CTg0GFPoAJLsDQlpvKc9ORlx6SgYnynCfmpcNkkNDv8aHJMaAu5Q7VqG6Eqb89O82MLKsJPS4vjnf2YZqmfNXdH/sSagC6WTdivku4JdSAkpmxmQ0Y8PjVLDLLR+Hxp0IJNVqrkCLRvuE9/K9VahpZZGBaelzq1bWWaOA1GSRkWU1qL8N4msbb1edWs0TnTlTmXIQO6hpqKbWagbGakJNmCXzOF3bDvbHm9vrVoHJqQQaK7DZ1OazT7UNnn0cNHETqP9aVSGLF2bKZStPmq7sbMeOeN3D2fW9i9/EuNdALLVGIlS3ffGoHzvrxG3h0w2cY0DRmjlUGZiT9L0CwPKEOsguZU5Ko4EUwGCTdkuw0zQlem4GpyEtXMyEVeWnIzdC/p0QrIZmNBkzMV/7uow1rjLQRpiRJKNeUkX616SDmPbABh1p7g1N4YyyraRtwW3qU7xcpgJEkSc2mifk3DGDC40+FEmosm3gB4Jpzy5FhMeI7l03DlZoR4jnpZmQErvLCbeooAoPcDAskSUJBYDXJeFqJJLIvpdk2nFmiBGYfBFZcCdF29AX0y4OzbCZ1gNh4XIkksgCAkqoHlN8vMejreGefGmDOnqBctcc6C0ZkYBacWYgFZxaqn3e6fXj/YLsaOKWH9BNdPrtEN+r+r3Un1GMwG6WYxsonUnVlPuw2E5bMiL6lxlBEBsbl9evnlIzS80k3h8/AAMA3LpqM/AwLLjurGLmhGZgoAQygaeSNsAUEEMzahQsCKwLB02fNPfjVO/Vod7rx9v6WuGbAAErAJrJ5agYmys+2UPM7DrD/JRKWkCihxrKJFwDOmZiLT+5bNqheLEkSKvLSsb+pB/saHcjPsOjq6WIjR7GRmigbjadZMOIqcmphhjol1BkSsDiHmAXTF8jQZFhNMBgkZKeZ0dXnQXefZ0Q9FKeCOElkWU26oKEiLx0tPS40dPSrc2BmlWVj46ctcWRggjtH/+Gb56PP7cOjGz7Dk+8dRkvPgHp1nBZygvzKeRW4am4ZOpxuXPTQ2zja3oejgSbavEDwO5qmFWWh7p6lI240D2Zg/CFzSkbnb1g08U7IGdzn8q1LpuJbl0wFoEzMtZgMaqkr2iokQNsHEy0DowS94ZqgRSPvU1uPqFm24539akYknou0NIsyIFOUhSI18QLBabyiQZsZmPD4U6GEGssmXiHSSUSc9L/zp49wzgMbsOb1T9XbxAlNXOGJEtJ4WkotriKnFmSqJbFQQ2dggjssAwg28o7DDIxjQKTp9b9HoqRwqLVXLXWI0lKs+yGJElJuuhmSJCHDalJ7JFp6XMESUpgVXTazEWU5aZgQuP+7B5UyXv4ozoDRSsQqOW0TrzhR28yGuCbvjoTIdIVOOA4lSZKuD2bIDEyBWPoeOQPTGCUDI37XtIHx8c4+tbk2njK5CIY3HVDGhkTLwIgA5h97mgAwgImEPxVKqLHugYnmn6tKdQHWyx+eUAe/aa/IgWAvw3ja0FFcRVYWZqhNyYIojw2VgREZG3H/7PTxOwsm0mZ5Inj7+HgXAKVvSUwVbuweGHKYHxAsGWobtMVJo7XHFSwhmSOfZMTJdstnyglpNGfAJJq2iTfY/zJ6f7+XnFGIoiwrvhyYqB2NaD4Hok/iBYDKoqEzME1qD8zgJt9wFwoNHf3BJt702H9GV84pgUFSGsftNhMWnFEY8b6LZxYjy6qUeI0GCZfPKol439MZS0iUUGljuAppKF86ZwK+dM4EDHh8mHvfm2jtcaG+1YlpRZnqCU3MRhHzPBo6+3Wb92k39QMAp0vZI+ZUlg66+zzo6HPj8xZRQhqcgTmjOAt1DV1qiSgSkYERqyLEc4lnJZJo9Ex0Y2eo4FWu/m1KBG9itk9ehkVN/7u9fnQ43YOaaWVZRq/LiyybGV6fX10Gqy1XFGoCmPJAdiXNEvkab1aZHRv2NasDE0PH5icTbRNvtJ2ST5Xqynx88KPFMd1XG3RahyohBTIwJ7sH0Of26lYDCdEyMNp906YUZOBwmxMNnX2aHpjYf0Y/Wj4TP1o+M6b7XnJGIfbcx9lnQ2EGhhJKZGAsRsOQ6d2xYjMbMW+SsoqnNrCKR2Qg8gKrHEQ5YMtnrbj0vzep/y786Vt4e7+yV9eHxzpx4U/fwupnPzxlx3qotRfnP7gRl/73JjWQmlqYgZx0s9qnIUnB4Xt9MTbxpoeUkLpinAXj9fmx9LEtuGLtuzGP7R+uSEtVRfDWptlA0WIK7rsTrg/mgVc/xdn3b8Ce493o7vdAJGlyNI+tzcAEl5tHPkFpV8sAo7+EOpG0GZhel5hxMj6vb7VB51AZmNwMi9rXFq6Rt8/tVX/PopWQAOC7i84IfI0PRwIbqo63i7TTDQMYSqjJ+emYPyUP154/vncCF/usbA3MUVFXIQUyMBdOzcMZRZnIsprUf2KX6tufq0NdQxdWP/Mhelxe7AzsoHsq7DnRDbfPD2NgefeSmcWYkJOmLPEMvLmW2G3qibgvjiZeIJiOj7UHprF7AEfb+3Co1akboHcqBPeaCQlgQnYTF9kycQIKNwtm82ct8PllfHCkQy0X2m0m3V40IgPT6/Kqvw+hTbxaoatlRnsJdSJZjMEemNAl1ONNrraENEQGBgDODJQXP210DLpN/K5kWk3qSjetDKsJ110wEYvOKsKVc0pRHJiS+2kg6zZWfX6kGJ+/oZS0TEYDnv/2+N94U8yL2XaoHX6/HKaJ14oNd35B9zVurx9f/XUt6hq68OVfvQ+RgIh08m/oCKaapxVlDisjJRpZF88owq//7TzdbeW5yqqqitx0pAdONkNmYDz6AW3BDExsAYy2SbbX7Y2rByBe6qyNkBNLSbYNBgnqz1+UFEqybdhzohuNIY28Xp8fxzqCO3d3qtk2fcYkUxOkHu1QrtajBTCl2TbkppvVx0uFHhiXJ9jEO14DGG0Tb7RJvMKssmxsP9yBvScd+ErIbU0RZsBorfnyHPX/y3PT0exwqVsPjLc+v9MNMzB0Wqoqz0G6xYjOPg8+Pt6lppdDB2VpWUwG/HLFuchNN8MvB1cGuLz+QcPx3jnQgksefgf//D/v4Z//5z1c/7/bhnWcjigTP0UvSHlumloSGnoZtRhkF9LEG0cGRtAutz0VIpWQzEaDbmqqKPeJDMzJkN2lGzr74fEp0c7xzj7dzB8tSZLUfWiaHUrzdugcmND7i9VPynEkbwAjemDcPp9uI8fxSFdCiiEDIzJl+04OzsBE638JpyJX3+jLEtLYYgBDpyWz0YDzJ+cBAFY9vQsnuvqRl2HBvIl5Ub9uQk4anvj6PJw/ORe/vP5cmAJLWEMzGJ8c7wYQfIPdc6I7ptUxoaIt1/zS2RNQVZ6Nf51Xrq4qinmQXaC3I95l1NpBcb2nOIAJlpAGn0i1q7BE5kNMyf2sqUd33/qW4AqU45396hC70KFoQHAnYGGorJl22W8yl5DCZWCizSkZSyJzJkmxDXibFRhyuPdk96C+LXUGjD3GACakfJk9BrOuKIgBDJ22RB9Ms8MFSQLWfu3smEoi86fm48VVF2HJzGLNKh59E6zYLHDF/EkAAI9PVstBPr+MD491ora+HbuOdsAXpRlWnMTDZWDmVuTgb7f9Ey6aVqAGJKGD7UJpN3MEND0wMTbxjmYGJmr2SbMKS/TAzApkQ/aGXGlrN8Bs6OhTX5twAYzIwAjRdvYG9I28yZyBESvK3D5ND8w4zcCIlYI2U2yr/6YVZsJqMsDp9uFoyF5o8Wdg9AEMS0hja3z+hhKNAu2+SbcvOhOXRJnLEEl2uhntTvegDIy4yi+x29QN4dp7XchOM+OxDZ/hF+8cVO978bR8/OGbF+gaSoVIs1BCBTMwsc2BSQsJYGItITWNQQAT7iRRrjmRiBLSjFI7JEnp02nvdakZkfqW4OoTp9unlgvzwpQLQzMw0UpIgL6RN5l7YNRyqK4HZnyenEWgOFRwKZiMBpxVkoWPj3dj78luTAlk6oDoM2DCKc9jCWk8YQaGTluzy7LxtfMrsLJ6Ev7fZdOG9RiRmmDVSa8ZFvXEJnovPjmplJeK7VZYTQa8f7Ad//3mZ2EfP9ZN40QT71CbOfarg+zEHJj4BtlpMzC9Q3yvkYoWvIUrIWVaTZicr5yctFkYbQYGAPYEyns5YTMw+ivxaE28gFK2uu6CCnzrn6aEnTGSLMRmg26ff9z3wJxVkoXlc0pxy4KpMX/NzLLw2bmRZGAspvE7KuJ0MT5/Q4lGgcEg4aFrqkb0GOIk2B1SQgquajIjL8OCI+196twSsZnbQ1+uQp/bh9XPfognNtdj3qRcLJmp35QvUiNrKJEpGGoZtdOtb+IVGRjHgAc+v6zbcyicUc3ABE6k4RuYB2dgAKUn5XCbE3tPOtRNGsUY+UyrCb0uLz5vUXpkQlchAcGl1MJQJyhJkrDmyyP7HRoPrKbgIDuxz9B47YExGZVm+niITFloACNW1UVbhaRVmm2D0SDB55e5hHocYAaGaAQiZWC0K13UbQkCG0O2BAKYwiwrlleV4psXTwYA1Ly8Z1Cjr9rIOkStPRjAxNfEK96EZVm/+3M4Xp8fLT3aDMypC2BkWQ6WkMJknyZqAxhN6Wa2eqWtZFm6+tzqayFKhqLlKGwTb1Z8JaRUoWZgvH51ifB4XUY9HMGVSMFm+v1NDvV3I9YMjMloUO872juP02AMYIhGIDtCD4k62TfdojaZtve64fPL6v5KYvLrD684CyaDhLZe16DNCKM1smqJ8kW0AMbj86tX16Jnxmw0qP8/VBmppccFbb/xqQxg+tw+eAPfLNxzL7bb8O0vTMV3Lpum2zE59EpbZF9Ks23qfklCuAxMUZwZmFShHQnQGwhkx2sJaThmlNphNEho63WjpceFngEPbn1amaC96KyisOXESEQZif0vYy91fkOJxkBOmB4S7X4yuekWtcTR3utCu1MJAiQpeAK1moyYmJ+OQ61OHGp1qjNOZFmOuCNzqAxNCUmW5bCrM7TBjbYBMifdAqe7XxeEtTgGcLyrH+dOzFU/FzqiP9ElJFmW8cHhDswos6uPbTJIEftQaq6YMehzIoA53OZEr8uL+laxf9TgDTBzw6w402ZgrCbDkCW1VCFWIbX1uNRhh6mUgbGZjagszMBnzb34w9YjONDUg8NtTpRl2/DIV+bG9VgVeWmoPcQpvOMBMzBEI6D2kGhO/iKYMRokZNlMaomjzelGS2BAWn6GVbfqSGw6V6/ZNdfp9qlLrIcsIQVONn5ZuYoORzTwmgySbn5GdphZMLc+8yG+/KutaikGGDyiP9EZmP9+8wCu/c02/H+v7tM18MazUWZ+plWd6fFpo0NdcVQZZgPM0EF2gPK6iJgl1lUuqUCUyk52D6i/v6l2ghblxV9tqsdb+1tgNkr41dfnhc3ERTMp0CgergRJoyt1QmyiMRBchhxs4g3uq2SGwSAFe2B6XWgNKR8JlYUZ2PipfsM5cRJXNsaMfq2hzVL0uX1hSx+igTctZPds9TloZsEcCWwcuelAqzrrpLFbP+E2kRmYjfua8ct36gEou0yL1VfDOYnOKrOjyTGAvSe6gxmYgoxBQ8hywjy20SChINOKlh7XkCuQUklVeQ5WzJ+Io4FNCmdPyNZtZJgKbl4wFY4BDwY8yt5iN1RPwtkVOXE/zjXnlqO+pRffCPSu0dhhAEM0AvYwTbxiBZKoqxdkBJdRtzqCDbxalYWDMzDaJtahshBGgwSb2YABjx9OlzfsVWXoEmohdENH7d5QW+vbsPpSZYm5yMAUZlnR2uMacsn2UA619mJrfTv8soz/Xn9A/fyRtuC4/+E0Ss6akI239rfg9U+a1D2QphZm6laQhG7kqFWYFQhgTqMMjNEg4cF/mTP0HZPYjFI7frvy/BE/Tkm2DY9ee/bID4hGjAEM0QiEW4XU6Qw28AJAnqaJN1IGZmqhkpYOl4GJtVkw3WLCgMcdsZFXZEzSrfoTc+gsGMeAR23W3XmkEy6vD1aTUd0kcVphJlp7XCMuIX3rDztxqC34fM+uyMGnjQ64vH7sC+wcPJxGyTmBibzbD3eon5tWlAmT0YASu03dNiKSoiwr9mLoGTBENLbYA0M0AsE5MMEARh1VH5j0Kpp4O/rcahkmNAMzNZCBOdHVr2ZKok2iDWeoWTCiOTN0aXCwhKR8v05dQ7IfHx3rAhDMwJxRrBzrSEtIoin4C2cW4usXTsRv/m2eOiW1rkH5nsMJYBZOL8Q3L56My2eV4PJZJai54iyU5SjlENHIG67/RRCvDQMYovGNGRiiERAZmF6XFx6fH2ajAV2B8oe4ys9NN0OSlFkrnzUpJaLQDExehgW56WZ09nlwqK0Xs8qyY16BJAw1C6bPJQKYkBJSyH5OonwjbK1vx4VT89EY2OV5WlGm+pyHS5ZlDHiV43nkX6vUCbiVhZnY39SDumOdAIa314zZaMBPrpoV9raK3HRsQ0fUBsyiLOVYTqcSElEyYgaGaAS0wYXIwnSE9MCYjAb1hPlpk1IaCR1ZDwSzMKKMFOsUXmGoWTCiiXfIDExIALOtvh0+v4zmwAC+aYUjD2DcPj/EzD6rJtMhSmnRpvCOxORAhic0gNQS2ZpUW4VDlGqYgSEaAaNBgt1mgmPAi64+DwoyrWoAkKe5ys/PsKDD6VZ3+g0tIQHKSpldRzvVRt5gCSm2P1OxPUCkElKkJt6CwCopscWBaOCdUpCBw21OfNTQiYaOPnWrAREEOF2RZ84MZcATXOqtXWElAhhhqD2g4nXdBRPR6/Liq+dVRLzPVXNLcaKrD1fNLUvo9yaixGIGhmiEQvdD0m7kKITuVBwuA1BZNLIMTJo5tgxMaGlEBFOhAczc8mxMyEmDxyfj/lf3qcctsk5+WQlEuvs8+GPtkUGlp2hcgX4cSYJuJo1YjSUkOguSl2HBXZefpduROFSWzYzvLzsLZ5XYI96HiMYeAxiiERrcBBucAyOIWTBCpAwMENw9Wd0HKcaTuMjARGquDWZg9AGM6Plo63XB75fR4QwGYBdPU/YPent/CwBlE8V0Tcmn1+XFH2uP4J6/7sX/vnsopuMEghkYm0k/kyY0sBhODwwRnR5YQiIaoeyQpdTajRyFfM3/Z1pNgxppAX0PjG4zw7hXIUVaRh1o4g0ZEZ+faYEkAd7A/Bcx0C4v3YJbFkxFboYFLo8fBknCNfMmwGCQkGExwun2wenyqrNWjnfqB91FIxp4Qwf0ZdnMKArMYQG43wwRRcYAhmiEQkfxh++BCWZcIjWQTspPh8kgoc/tQ5NjIO5ptEM18fZ7Ak28IcuDzUYD8tItaHcqG91pA7DS7LSwew5lWE1wupU9n0SwITap1Pq8uQdv72/Byosm66YDD3hEADN4pU9lYab6mGykJaJIWEIiGqEczY7ULq8PzkAAoV2qq+2BKYgQwJiNBkzMV8bdf9bcqykhxXadMdQcmEgZGCBY0mrpcWlKYJGXGoudintdXrV3JlwPzEOv78ea1/fjzX3Nus+rJaQwAYy2kXc4k3iJ6PTAAIZohMSO1N197kEbOQoFmgAm2hLeGaVK4+i+k46EL6Pui7CMGtA38gYzMJG/r9ip2KnJwLT1Dg5gRFnpWLtT93mRgbGaBr8FTdU08jIDQ0SRMIAhGiFtBiZ0I0dB28QbroFXmFWmBDB7T3bH3QMz1DJqEdiEC2BEI29LT3A34mjj9sVSbMeAB+1OkYFRmoC1WnqUabuNITtZRy8hBTMwWWziJaIIGMAQjZC2iTd0I0dB28QrgoVwxM7Pu493q6WoWBtZxej7yMuow0/iBTQlJEdsJaSMQAbmaHufOpDOLytBnOD2+tUl5U0hAYzLK0pIg9+CziqxwyAp82ksYTI0REQAm3iJRkwEK139nkEbOQraDEy0EpLIwIiVPUA8g+wCJaQIu0T3BzIzocuotcdU39qrbuSYkx6thKQ8xpE2fWmovdelZm7aNE298WRgSrJt+N03zo8aQBER8fKGaITEib67zz1oI0fBbjPBbFRKStFKSAWZVhTbg7dnWIwwGWP7MxUD6vo80Zt4w+3xI45pf1MPAKXHxWqKvBeQCJYOhwQw2j4Y0RsDAE2OkADGG5wDE87C6UWYW5ET8fsTETGAIRqh4GaIHnUJdWj2QJIkTMrPgCQNHtYWanagjATE18Qq+lIiZmACWY+MMKuQikKm8UbLvgDBJt5DoRkYZzBoadUEMB1Ot5p1AYKTeMOVkIiIYsESEtEIZacH58CEG2In/O8N56Gxqx8VeelRH29WmR1vBSbfxjPITTTnOiMuo468Cil0c8loDbxAMIARezsJ2qXUooFXaHYMYFK+ErxFKyEREcWClz9EIySyJLIMvLq7EcDgHhhAybxcNK1gyMebqcnAxDNKP9okXp9fVhtnozXxCkP1n4TL4gAhJSSHfrCdtg8m2hwYIqJYMIAhGiGryYgJOWkAgo2rk4coE0UjGnmB+DIwahOv2wdZ1i9n1i6tDpeBUbY3CH4+N8YSUuj9tdN4W3tDA5jgVgPqHBiWkIhomFhCIkqAP918IXYe7QCglF8WnFE47Mcqz01DdpoZ3f2emKfwAsHmXJ9fhtvn1zXhiqyMQQo/PA5QsjBH25XVT+FKYFqhGZgZpXZsrW9He5gMjEFSlljrMjBeMciOGRgiGh5e/hAlwMT8dHz53HJ8+dxyLJxepBtiFy9JktQsTDxNvNo9jr76RC2+9YcdakaoT92J2qTb/VlLu7w7XAlMSwzNE84qUY5X18Qb+N5nFGUB0M+CCZaQ+BZERMPDdw+icah6aj4AYGocpSiT0YDyXKWU9fHxbmz8tAV/rTsJQGmgBYINx+FoB+zlxNjEK8woVYIUbQamNfA9q8qVnh59D0ygiZcZGCIaJpaQiMahb3+hEv90RgGqynPi+ro/33oRPm7owht7m/Dyhyew92Q3AGDvSQeA4F5L4RTGlYEZXEICgj1AsiyrGZiq8my8uOt4hAwMAxgiGh5mYIjGIYvJgHMm5sIYZymq2G7D0lkluHJ2KQBlU0gAaiCjbRAOpQ1gom3kCOgzMFk2k9rE7Bjwwu31o6vPA49PaSSePWFwBsbl5RwYIhoZvnsQpaBZE5RA5fOWXgx4fGogM0uzRDuULoAZIgOjDWCKsqzITjOrwVZnn1udwpuTblZnv7T1uuAOLOXmHBgiGikGMEQpqMRuQ16GBT6/jN3Hu/F5Sy8AYPaEyBkYXRNvHKuQCrOsMBgkNehp63WpU3iLsqzITTermzKKXhw28RLRSMX17rFu3TpUVVXBbrfDbrejuroar7/+unr7woULIUmS7t+qVat0j3Hs2DEsX74c6enpKCoqwve//314vfppnps2bcK5554Lq9WKadOm4amnnhr+MyQ6DWlXMr3y0XH4/DLyMiwosUfeCVubgRlqKwGLyQBLYI8m0fxbkKkEMO29bnUKb1GWDZIkoTRbuY8oI7GJl4hGKq4Apry8HA899BB27dqFnTt34rLLLsPVV1+NvXv3qve5+eab0djYqP57+OGH1dt8Ph+WL18Ot9uNrVu34g9/+AOeeuop3HPPPep9Dh8+jOXLl+PSSy9FXV0dbr/9dnzrW9/C+vXrE/B0iU4folz0948bAx/bIy6hBoDJ+RnITjPjzOLMmOaziKXUInOTLwIYp0stIYmgSAROYpidOgeGJSQiGqa4ViFdddVVuo8ffPBBrFu3Dtu2bcOsWbMAAOnp6SgpKQn79W+++Sb27duHjRs3ori4GGeffTYeeOAB3HXXXbj33nthsVjwxBNPYMqUKfjZz34GAJgxYwbee+89PPbYY1i2bNlwniPRaUlkYHoDeyDNjNLACyhloc3fX6iWe4aSYTWhs8+jBin5Gcp/23vduhISAJQFmnybullCIqLEGPa7h8/nw3PPPQen04nq6mr188888wwKCgowe/Zs1NTUoK+vT72ttrYWc+bMQXFxsfq5ZcuWweFwqFmc2tpaLF68WPe9li1bhtra2qjH43K54HA4dP+ITmehK46iNfAKOemWsHslhSMaeYvs+gxMW697cAYmUgmJGRgiGqa458Ds2bMH1dXVGBgYQGZmJl555RXMnDkTAHD99ddj0qRJKCsrw+7du3HXXXfhwIEDePnllwEATU1NuuAFgPpxU1NT1Ps4HA709/cjLS0t7HGtWbMG9913X7xPhyhlTc7PQIbFCGdgCu/sITIw8Tq7Igf1rb2YG5hVU5CpBCsdThdaAs26IoApDNwm5sS4OAeGiEYo7gBm+vTpqKurQ3d3N1566SWsXLkSmzdvxsyZM3HLLbeo95szZw5KS0uxaNEi1NfXo7KyMqEHHqqmpgZ33nmn+rHD4UBFRcUp/Z5E45nBIGFmmR07jnQiw2LE5PzhbzAZzpovz8F/Lp+h7pgtVi6197rVIXaiwVdsieAY8MIf2KsJAGwxlquIiELF/e5hsVgwbdo0zJs3D2vWrMHcuXOxdu3asPedP38+AODgwYMAgJKSEjQ3N+vuIz4WfTOR7mO32yNmXwDAarWqq6PEP6LTnSgbzSi1j2h/pnAkSVKDFwDIDwQwb+1vwaFWJ4BgBkbsqu3o98AVmAUDMANDRMM34ssfv98Pl8sV9ra6ujoAQGmpMhW0uroae/bsQUtLi3qfDRs2wG63q2Wo6upqvPXWW7rH2bBhg67Phohi889VpTAbJXzx7LJT/r3mVuQgSzMfZmJeOirylIsOu035vKPfo/a/AAxgiGj44ioh1dTU4IorrsDEiRPR09ODZ599Fps2bcL69etRX1+PZ599FldeeSXy8/Oxe/du3HHHHViwYAGqqqoAAEuXLsXMmTPxb//2b3j44YfR1NSEu+++G6tXr4bVqlyprVq1Cr/4xS/wgx/8ADfeeCPefvttvPDCC3jttdcS/+yJUtx5k/Pw+YNXjsr3KrbbsOPuxXD0ewAAuRkWmAOzYsQmko4Bj7qE2myU4t4qgYhIiCuAaWlpwQ033IDGxkZkZ2ejqqoK69evx5IlS9DQ0ICNGzfi8ccfh9PpREVFBa655hrcfffd6tcbjUa8+uqruPXWW1FdXY2MjAysXLkS999/v3qfKVOm4LXXXsMdd9yBtWvXory8HL/97W+5hJooCdjMxrBZFVFq6u73BJdQc4gdEY1AXAHMk08+GfG2iooKbN68ecjHmDRpEv7xj39Evc/ChQvx0UcfxXNoRDSOiSZej09GZ58bAIfYEdHIcAkAEZ1y6RajWi5qcSg9c1auQCKiEeA7CBGdcsqKJSXh2xrYJ4lTeIloJPgOQkSjQpSRmgMZGK5AIqKRYABDRKNCzIJpUTMwDGCIaPgYwBDRqBArkYIZGL79ENHw8R2EiEZFtpqBCQQwXEZNRCPAAIaIRoU9LbSJlwEMEQ0fAxgiGhWiB6bdKebA8O2HiIaP7yBENCpED4wsKx8zA0NEI8EAhohGhcjACOyBIaKRYABDRKMiOzSAYQmJiEaA7yBENCrEJF6BJSQiGgkGMEQ0KgaVkJiBIaIR4DsIEY2KwSUkZmCIaPgYwBDRqBCrkAQ28RLRSDCAIaJRIQbZCZwDQ0QjwXcQIhoVVpNR1/fCEhIRjQQDGCIaNdoyEgMYIhoJBjBENGq0jbxWE99+iGj4+A5CRKNGu5SaGRgiGgkGMEQ0arJ1AQzffoho+PgOQkSjRjuNl8uoiWgkGMAQ0ahhCYmIEoUBDBGNGpaQiChR+A5CRKOGy6iJKFEYwBDRqNFO4+UyaiIaCb6DENGoESUkq8kASZLG+GiIKJkxgCGiUSNKSCwfEdFIMYAholFTnG0DAORnWMb4SIgo2ZmGvgsRUWJUFmbi8WvPxuSCjLE+FCJKcgxgiGhUfemcCWN9CESUAlhCIiIioqTDAIaIiIiSDgMYIiIiSjoMYIiIiCjpMIAhIiKipMMAhoiIiJIOAxgiIiJKOgxgiIiIKOkwgCEiIqKkwwCGiIiIkg4DGCIiIko6DGCIiIgo6TCAISIioqSTsrtRy7IMAHA4HGN8JERERBQrcd4W5/FIUjaA6enpAQBUVFSM8ZEQERFRvHp6epCdnR3xdkkeKsRJUn6/HydPnkRWVhYkSRrx4zkcDlRUVKChoQF2uz0BRzj+pPpzTPXnB/A5poJUf34An2MqOJXPT5Zl9PT0oKysDAZD5E6XlM3AGAwGlJeXJ/xx7XZ7Sv4yaqX6c0z15wfwOaaCVH9+AJ9jKjhVzy9a5kVgEy8RERElHQYwRERElHQYwMTIarXiJz/5CaxW61gfyimT6s8x1Z8fwOeYClL9+QF8jqlgPDy/lG3iJSIiotTFDAwRERElHQYwRERElHQYwBAREVHSYQBDRERESYcBTIx++ctfYvLkybDZbJg/fz4++OCDsT6kYVmzZg3OP/98ZGVloaioCF/60pdw4MAB3X0WLlwISZJ0/1atWjVGRxy/e++9d9Dxn3XWWertAwMDWL16NfLz85GZmYlrrrkGzc3NY3jE8Zk8efKg5ydJElavXg0gOV+/LVu24KqrrkJZWRkkScJf/vIX3e2yLOOee+5BaWkp0tLSsHjxYnz++ee6+3R0dGDFihWw2+3IycnBTTfdhN7e3lF8FtFFe44ejwd33XUX5syZg4yMDJSVleGGG27AyZMndY8R7rV/6KGHRvmZhDfUa/iNb3xj0LFffvnluvsk82sIIOzfpSRJeOSRR9T7jOfXMJbzQyzvn8eOHcPy5cuRnp6OoqIifP/734fX60348TKAicHzzz+PO++8Ez/5yU/w4YcfYu7cuVi2bBlaWlrG+tDitnnzZqxevRrbtm3Dhg0b4PF4sHTpUjidTt39br75ZjQ2Nqr/Hn744TE64uGZNWuW7vjfe+899bY77rgDf//73/Hiiy9i8+bNOHnyJL785S+P4dHGZ8eOHbrntmHDBgDAV77yFfU+yfb6OZ1OzJ07F7/85S/D3v7www/j5z//OZ544gls374dGRkZWLZsGQYGBtT7rFixAnv37sWGDRvw6quvYsuWLbjllltG6ykMKdpz7Ovrw4cffogf//jH+PDDD/Hyyy/jwIED+OIXvzjovvfff7/utf1//+//jcbhD2mo1xAALr/8ct2x/+lPf9LdnsyvIQDdc2tsbMTvfvc7SJKEa665Rne/8foaxnJ+GOr90+fzYfny5XC73di6dSv+8Ic/4KmnnsI999yT+AOWaUgXXHCBvHr1avVjn88nl5WVyWvWrBnDo0qMlpYWGYC8efNm9XNf+MIX5O9+97tjd1Aj9JOf/ESeO3du2Nu6urpks9ksv/jii+rnPv30UxmAXFtbO0pHmFjf/e535crKStnv98uynPyvHwD5lVdeUT/2+/1ySUmJ/Mgjj6if6+rqkq1Wq/ynP/1JlmVZ3rdvnwxA3rFjh3qf119/XZYkST5x4sSoHXusQp9jOB988IEMQD569Kj6uUmTJsmPPfbYqT24BAj3/FauXClfffXVEb8mFV/Dq6++Wr7ssst0n0uW11CWB58fYnn//Mc//iEbDAa5qalJvc+6detku90uu1yuhB4fMzBDcLvd2LVrFxYvXqx+zmAwYPHixaitrR3DI0uM7u5uAEBeXp7u88888wwKCgowe/Zs1NTUoK+vbywOb9g+//xzlJWVYerUqVixYgWOHTsGANi1axc8Ho/u9TzrrLMwceLEpHw93W43nn76adx44426TUuT/fXTOnz4MJqamnSvWXZ2NubPn6++ZrW1tcjJycF5552n3mfx4sUwGAzYvn37qB9zInR3d0OSJOTk5Og+/9BDDyE/Px/nnHMOHnnkkVOSmj9VNm3ahKKiIkyfPh233nor2tvb1dtS7TVsbm7Ga6+9hptuumnQbcnyGoaeH2J5/6ytrcWcOXNQXFys3mfZsmVwOBzYu3dvQo8vZTdzTJS2tjb4fD7diwEAxcXF2L9//xgdVWL4/X7cfvvtuPjiizF79mz189dffz0mTZqEsrIy7N69G3fddRcOHDiAl19+eQyPNnbz58/HU089henTp6OxsRH33XcfLrnkEnzyySdoamqCxWIZdFIoLi5GU1PT2BzwCPzlL39BV1cXvvGNb6ifS/bXL5R4XcL9DYrbmpqaUFRUpLvdZDIhLy8vKV/XgYEB3HXXXbjuuut0G+V95zvfwbnnnou8vDxs3boVNTU1aGxsxKOPPjqGRxubyy+/HF/+8pcxZcoU1NfX4z//8z9xxRVXoLa2FkajMeVewz/84Q/IysoaVJ5Oltcw3PkhlvfPpqamsH+r4rZEYgBzGlu9ejU++eQTXX8IAF3Nec6cOSgtLcWiRYtQX1+PysrK0T7MuF1xxRXq/1dVVWH+/PmYNGkSXnjhBaSlpY3hkSXek08+iSuuuAJlZWXq55L99TvdeTwefPWrX4Usy1i3bp3utjvvvFP9/6qqKlgsFnz729/GmjVrxv3I+q997Wvq/8+ZMwdVVVWorKzEpk2bsGjRojE8slPjd7/7HVasWAGbzab7fLK8hpHOD+MJS0hDKCgogNFoHNRl3dzcjJKSkjE6qpG77bbb8Oqrr+Kdd95BeXl51PvOnz8fAHDw4MHROLSEy8nJwZlnnomDBw+ipKQEbrcbXV1duvsk4+t59OhRbNy4Ed/61rei3i/ZXz/xukT7GywpKRnUVO/1etHR0ZFUr6sIXo4ePYoNGzbosi/hzJ8/H16vF0eOHBmdA0ygqVOnoqCgQP29TJXXEADeffddHDhwYMi/TWB8voaRzg+xvH+WlJSE/VsVtyUSA5ghWCwWzJs3D2+99Zb6Ob/fj7feegvV1dVjeGTDI8sybrvtNrzyyit4++23MWXKlCG/pq6uDgBQWlp6io/u1Ojt7UV9fT1KS0sxb948mM1m3et54MABHDt2LOlez9///vcoKirC8uXLo94v2V+/KVOmoKSkRPeaORwObN++XX3Nqqur0dXVhV27dqn3efvtt+H3+9UAbrwTwcvnn3+OjRs3Ij8/f8ivqaurg8FgGFR6SQbHjx9He3u7+nuZCq+h8OSTT2LevHmYO3fukPcdT6/hUOeHWN4/q6ursWfPHl0wKoLxmTNnJvyAaQjPPfecbLVa5aeeekret2+ffMstt8g5OTm6Lutkceutt8rZ2dnypk2b5MbGRvVfX1+fLMuyfPDgQfn++++Xd+7cKR8+fFj+61//Kk+dOlVesGDBGB957L73ve/JmzZtkg8fPiy///778uLFi+WCggK5paVFlmVZXrVqlTxx4kT57bfflnfu3ClXV1fL1dXVY3zU8fH5fPLEiRPlu+66S/f5ZH39enp65I8++kj+6KOPZADyo48+Kn/00UfqCpyHHnpIzsnJkf/617/Ku3fvlq+++mp5ypQpcn9/v/oYl19+uXzOOefI27dvl9977z35jDPOkK+77rqxekqDRHuObrdb/uIXvyiXl5fLdXV1ur9NsXJj69at8mOPPSbX1dXJ9fX18tNPPy0XFhbKN9xwwxg/M0W059fT0yP/x3/8h1xbWysfPnxY3rhxo3zuuefKZ5xxhjwwMKA+RjK/hkJ3d7ecnp4ur1u3btDXj/fXcKjzgywP/f7p9Xrl2bNny0uXLpXr6urkN954Qy4sLJRramoSfrwMYGL0P//zP/LEiRNli8UiX3DBBfK2bdvG+pCGBUDYf7///e9lWZblY8eOyQsWLJDz8vJkq9UqT5s2Tf7+978vd3d3j+2Bx+Haa6+VS0tLZYvFIk+YMEG+9tpr5YMHD6q39/f3y//+7/8u5+bmyunp6fK//Mu/yI2NjWN4xPFbv369DEA+cOCA7vPJ+vq98847YX8vV65cKcuyspT6xz/+sVxcXCxbrVZ50aJFg557e3u7fN1118mZmZmy3W6Xv/nNb8o9PT1j8GzCi/YcDx8+HPFv85133pFlWZZ37dolz58/X87OzpZtNps8Y8YM+ac//akuABhL0Z5fX1+fvHTpUrmwsFA2m83ypEmT5JtvvnnQRWAyv4bCr3/9azktLU3u6uoa9PXj/TUc6vwgy7G9fx45ckS+4oor5LS0NLmgoED+3ve+J3s8noQfrxQ4aCIiIqKkwR4YIiIiSjoMYIiIiCjpMIAhIiKipMMAhoiIiJIOAxgiIiJKOgxgiIiIKOkwgCEiIqKkwwCGiIiIkg4DGCIiIko6DGCIiIgo6TCAISIioqTDAIaIiIiSzv8PkrAF/EuxF/cAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(x_data , y_data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1zR-zxdJBJw"
      },
      "outputs": [],
      "source": [
        "# Normalize the data\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "x_data_normalized = scaler_x.fit_transform(x_data.reshape(-1,1))\n",
        "y_data_normalized = scaler_y.fit_transform(y_data.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data_normalized, y_data_normalized, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piPQbPEYJfpU"
      },
      "outputs": [],
      "source": [
        "# Function to create an LSTM model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.LSTM(10, activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV27U60LJukA"
      },
      "outputs": [],
      "source": [
        "# Function to train and evaluate the LSTM model with early stopping\n",
        "def train_evaluate_lstm(x_train, y_train, x_test, y_test, epochs=5, batch_size=1):\n",
        "    input_shape = (x_train.shape[1], 1)\n",
        "    model = create_lstm_model(input_shape)\n",
        "\n",
        "    # Implement early stopping\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_test, y_test),\n",
        "              callbacks=[early_stopping])\n",
        "\n",
        "    y_pred = model.predict(x_test, batch_size=1, verbose=0)\n",
        "    mse = mean_squared_error(y_test, y_pred.squeeze())\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCovdRsAJyLQ"
      },
      "outputs": [],
      "source": [
        "# PSO Objective Function\n",
        "def objective_function(params, x_train, y_train, x_test, y_test):\n",
        "    epochs, batch_size = params\n",
        "    mse = train_evaluate_lstm(x_train, y_train, x_test, y_test, epochs=int(epochs), batch_size=int(batch_size))\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRrCvIhoKDqA",
        "outputId": "fd6e5d06-7a62-48ab-d713-45fe2bf1d2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0213 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0249 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0264 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0306 - val_loss: 0.0111\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0239 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0238 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0221 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0253 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0254 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0267 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0228 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0290 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0241 - val_loss: 0.0121\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0241 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0241 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0263 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0280 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0144\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0236 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0247 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0236 - val_loss: 0.0119\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0243 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0233 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0285 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0236 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0244 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0236 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0226 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0281 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0253 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0247 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0273 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0223 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0239 - val_loss: 0.0118\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0293 - val_loss: 0.0120\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0235 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0221 - val_loss: 0.0142\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0264 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0241 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0233 - val_loss: 0.0138\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0215 - val_loss: 0.0137\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0256 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0267 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0224 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0264 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0234 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0311 - val_loss: 0.0113\n",
            "426/426 [==============================] - 5s 8ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0235 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0263 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0264 - val_loss: 0.0111\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0321 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0242 - val_loss: 0.0133\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0246 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0239 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0241 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0253 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0282 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0228 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0273 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0213 - val_loss: 0.0139\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0261 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0234 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0263 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0280 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0258 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0118\n",
            "426/426 [==============================] - 5s 10ms/step - loss: 0.0237 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0130\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0298 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0212 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0266 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0239 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0272 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0251 - val_loss: 0.0120\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0228 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0235 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0302 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0261 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0243 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0315 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0142\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0236 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0237 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0270 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0257 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0285 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0283 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0214 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0229 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0213 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0271 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0235 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0266 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0242 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0251 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0257 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0246 - val_loss: 0.0122\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0222 - val_loss: 0.0149\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0298 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0321 - val_loss: 0.0111\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0249 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0272 - val_loss: 0.0119\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0257 - val_loss: 0.0127\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0241 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0257 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0237 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0247 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0257 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0246 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0291 - val_loss: 0.0114\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0254 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0241 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0220 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0263 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0266 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0262 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0218 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0262 - val_loss: 0.0115\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0234 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0242 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0233 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0223 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0119\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0223 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0323 - val_loss: 0.0117\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0242 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0255 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0225 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0217 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0237 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0251 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0227 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0264 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0238 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0119\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0247 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0236 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0290 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0281 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0310 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0260 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0274 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0241 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0277 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0243 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0272 - val_loss: 0.0118\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0212 - val_loss: 0.0130\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0263 - val_loss: 0.0123\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0306 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0341 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0231 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0256 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0226 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0243 - val_loss: 0.0120\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0237 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0220 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0272 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0211 - val_loss: 0.0148\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0287 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0285 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0221 - val_loss: 0.0134\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0225 - val_loss: 0.0144\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0221 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0237 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0260 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0249 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0245 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0271 - val_loss: 0.0123\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0234 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0240 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0144\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0215 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0281 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0282 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0257 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0294 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0267 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0238 - val_loss: 0.0131\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0231 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0263 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0230 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0211 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0316 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0280 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0225 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0118\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0229 - val_loss: 0.0128\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0214 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0223 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0266 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0284 - val_loss: 0.0114\n",
            "426/426 [==============================] - 5s 8ms/step - loss: 0.0244 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0262 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0233 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0240 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0123\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0264 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0260 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0118\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0236 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0269 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0240 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0224 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0236 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0255 - val_loss: 0.0123\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0300 - val_loss: 0.0111\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0268 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0314 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0274 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0230 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0128\n",
            "426/426 [==============================] - 5s 10ms/step - loss: 0.0274 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0241 - val_loss: 0.0122\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0253 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0267 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0208 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0222 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0237 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0216 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0121\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0232 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0209 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0241 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0250 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0220 - val_loss: 0.0150\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0242 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0213 - val_loss: 0.0136\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0229 - val_loss: 0.0130\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0253 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0239 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0234 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0234 - val_loss: 0.0121\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0289 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0221 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0277 - val_loss: 0.0120\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0251 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0284 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0269 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0234 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0145\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0276 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0264 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0218 - val_loss: 0.0131\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0268 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0131\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0264 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0305 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0146\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0248 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0129\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0249 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0254 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0144\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0242 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0244 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0245 - val_loss: 0.0117\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0227 - val_loss: 0.0132\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0217 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0226 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0234 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0242 - val_loss: 0.0119\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0224 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0223 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0225 - val_loss: 0.0142\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0238 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0125\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0222 - val_loss: 0.0135\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0218 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0254 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0222 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0250 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0230 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0287 - val_loss: 0.0115\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0224 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0296 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0224 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0211 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0225 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0227 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0130\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0238 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0216 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0246 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0244 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0221 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0236 - val_loss: 0.0121\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0236 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0283 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0235 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0266 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0260 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0288 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0232 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0242 - val_loss: 0.0124\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0229 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0240 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0218 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0284 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0264 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0248 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0282 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0243 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0251 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0222 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0257 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0239 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0223 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 10ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0300 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0269 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0283 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0237 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0234 - val_loss: 0.0135\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0267 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0256 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0234 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0241 - val_loss: 0.0121\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0279 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0257 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0256 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0298 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0230 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0317 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0255 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0270 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0221 - val_loss: 0.0135\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0233 - val_loss: 0.0122\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0239 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0247 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0238 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0229 - val_loss: 0.0132\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0302 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0260 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0226 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0217 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0274 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0270 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0212 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0219 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0310 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0278 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0141\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0251 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0240 - val_loss: 0.0137\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0247 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0265 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0283 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0259 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0219 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0254 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0277 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0308 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0256 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0263 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0147\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0223 - val_loss: 0.0126\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0269 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0284 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0232 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0238 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0233 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0221 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0244 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0145\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0250 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0295 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0287 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0215 - val_loss: 0.0137\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0250 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0234 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0226 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0261 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0235 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0222 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0232 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0142\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0285 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0274 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0240 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0232 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0286 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0223 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0131\n",
            "426/426 [==============================] - 7s 7ms/step - loss: 0.0222 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0209 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0221 - val_loss: 0.0150\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0221 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0316 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0212 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0143\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0245 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0261 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0223 - val_loss: 0.0141\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0212 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0237 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0249 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0301 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0141\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0288 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0124\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0223 - val_loss: 0.0128\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0243 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0261 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0231 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0289 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0308 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0282 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0273 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0221 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0245 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0138\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0221 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0259 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0235 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0281 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0298 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0259 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0118\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0233 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0229 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0261 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0140\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0264 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0218 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0245 - val_loss: 0.0124\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0235 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0233 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0233 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0317 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0278 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0121\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0231 - val_loss: 0.0133\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0225 - val_loss: 0.0140\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0249 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0220 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0231 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0271 - val_loss: 0.0120\n",
            "426/426 [==============================] - 5s 10ms/step - loss: 0.0246 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0300 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0270 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0205 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0219 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0269 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0266 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0267 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0279 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0271 - val_loss: 0.0113\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0275 - val_loss: 0.0113\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0288 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0125\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0313 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0251 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0219 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0240 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0228 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0250 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0226 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0216 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0130\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0232 - val_loss: 0.0125\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0240 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0262 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0323 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0221 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0276 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0264 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0237 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0138\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0250 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 7ms/step - loss: 0.0256 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0233 - val_loss: 0.0154\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0231 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0293 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0236 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0263 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0274 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0231 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0144\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0306 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0128\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0222 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0245 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0252 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0145\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0215 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0289 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0317 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0248 - val_loss: 0.0121\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0238 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0224 - val_loss: 0.0139\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0268 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0242 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0274 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0299 - val_loss: 0.0113\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0236 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0217 - val_loss: 0.0132\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0217 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0280 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0250 - val_loss: 0.0125\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0221 - val_loss: 0.0126\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0214 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0264 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0251 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0252 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0214 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0256 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0116\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0272 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0257 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0241 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0247 - val_loss: 0.0127\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0284 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0138\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0241 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0273 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0211 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0235 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0217 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0142\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0256 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0230 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0216 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0281 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0226 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0239 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0283 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0244 - val_loss: 0.0126\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0232 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0223 - val_loss: 0.0141\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0210 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0287 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0257 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0291 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0331 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0335 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0217 - val_loss: 0.0128\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0242 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0239 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0287 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0302 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0272 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0143\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0257 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0250 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0256 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0141\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0223 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0213 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0119\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0239 - val_loss: 0.0123\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0320 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0233 - val_loss: 0.0139\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0250 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0230 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0130\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0250 - val_loss: 0.0124\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0257 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0235 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0274 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0236 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0303 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0235 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0235 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0242 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0217 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0230 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0230 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0231 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0244 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0238 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0273 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0294 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0229 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0218 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0247 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0304 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0213 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0220 - val_loss: 0.0143\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0217 - val_loss: 0.0138\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0294 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0220 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0266 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0246 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0271 - val_loss: 0.0119\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0239 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0245 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0142\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0264 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0240 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0257 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0266 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0225 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0288 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0280 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0282 - val_loss: 0.0119\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0257 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0227 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0250 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0268 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0255 - val_loss: 0.0117\n",
            "426/426 [==============================] - 6s 10ms/step - loss: 0.0257 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0243 - val_loss: 0.0123\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0223 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0226 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0243 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0267 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0276 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0230 - val_loss: 0.0120\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0243 - val_loss: 0.0126\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0255 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0214 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0276 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0303 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0292 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0248 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0268 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0264 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0271 - val_loss: 0.0115\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0246 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0233 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0274 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0277 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0267 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0274 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0270 - val_loss: 0.0118\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0225 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0240 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0231 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0235 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0287 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0220 - val_loss: 0.0134\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0227 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0279 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0239 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0269 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0246 - val_loss: 0.0120\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0241 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0254 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0232 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0248 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0271 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0125\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0248 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0230 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0309 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0262 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0214 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0289 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0235 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0235 - val_loss: 0.0123\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0222 - val_loss: 0.0137\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0254 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0266 - val_loss: 0.0111\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0270 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0212 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0233 - val_loss: 0.0129\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0211 - val_loss: 0.0126\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0304 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0268 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0247 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0248 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0261 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0299 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0225 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0227 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0218 - val_loss: 0.0147\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0222 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0365 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0219 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0264 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0246 - val_loss: 0.0127\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0246 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0249 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0226 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0262 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0261 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0282 - val_loss: 0.0115\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0215 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0256 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0271 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0309 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0231 - val_loss: 0.0124\n",
            "426/426 [==============================] - 7s 7ms/step - loss: 0.0258 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0267 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0226 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0281 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0142\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0227 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0309 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0263 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0130\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0234 - val_loss: 0.0129\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0238 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0275 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0248 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0256 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0231 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0290 - val_loss: 0.0115\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0292 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0264 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0225 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0223 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0247 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0214 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0281 - val_loss: 0.0115\n",
            "426/426 [==============================] - 5s 9ms/step - loss: 0.0215 - val_loss: 0.0129\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0212 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0247 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0212 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0226 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0295 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0219 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0252 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0240 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0226 - val_loss: 0.0126\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0264 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0230 - val_loss: 0.0150\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0254 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0247 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0245 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0251 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0224 - val_loss: 0.0148\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0255 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0124\n",
            "426/426 [==============================] - 7s 7ms/step - loss: 0.0213 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0287 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0263 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0247 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0244 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0257 - val_loss: 0.0115\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0250 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0270 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0216 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0264 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0270 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0264 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0266 - val_loss: 0.0118\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0270 - val_loss: 0.0114\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0271 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0340 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0250 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 7ms/step - loss: 0.0309 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0236 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0269 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0273 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0115\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0233 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0241 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0206 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0278 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0256 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0241 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0285 - val_loss: 0.0111\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0219 - val_loss: 0.0132\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0215 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0255 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0254 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0264 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0237 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0230 - val_loss: 0.0132\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0220 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0244 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0215 - val_loss: 0.0139\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0220 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0257 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0240 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0277 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0223 - val_loss: 0.0122\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0269 - val_loss: 0.0120\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0224 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0258 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0267 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0259 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0270 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0216 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0246 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0277 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0261 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0218 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0266 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0225 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0213 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0226 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0116\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0252 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0283 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0233 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0220 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0217 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0271 - val_loss: 0.0119\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0264 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0267 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0246 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0238 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0252 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0249 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0149\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0222 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0313 - val_loss: 0.0112\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0231 - val_loss: 0.0123\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0225 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0307 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0284 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0239 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0248 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0263 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0242 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0307 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0254 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0146\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0265 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0324 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0214 - val_loss: 0.0140\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0264 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0274 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0230 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0283 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0230 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0258 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0271 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0228 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0270 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0225 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0257 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0222 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0252 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0314 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0208 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0268 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0231 - val_loss: 0.0130\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0240 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0246 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0237 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0248 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0295 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0146\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0269 - val_loss: 0.0118\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0227 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0256 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0153\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0283 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0222 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0235 - val_loss: 0.0129\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0304 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0276 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0270 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0260 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0295 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0215 - val_loss: 0.0141\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0246 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0240 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0243 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0250 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0243 - val_loss: 0.0122\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0297 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0276 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0262 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0249 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0289 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0264 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0122\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0219 - val_loss: 0.0134\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0245 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0205 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0275 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0247 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0293 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0291 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0233 - val_loss: 0.0133\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0245 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0221 - val_loss: 0.0141\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0221 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0228 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0228 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0205 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0254 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0222 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0300 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0263 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0257 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0270 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0242 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0266 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0141\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0355 - val_loss: 0.0113\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0219 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0231 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0149\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0218 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0236 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0122\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0283 - val_loss: 0.0116\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0230 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0279 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0246 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0250 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0243 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0222 - val_loss: 0.0145\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0140\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0226 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0242 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0288 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0216 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0242 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0254 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 5s 10ms/step - loss: 0.0297 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0247 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0249 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0281 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0235 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0229 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0243 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0285 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0235 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0123\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0230 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0218 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 7ms/step - loss: 0.0257 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0264 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0260 - val_loss: 0.0111\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0127\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0246 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0256 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0311 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0277 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0240 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0124\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0252 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0241 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0326 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0223 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0216 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0274 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0266 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0126\n",
            "426/426 [==============================] - 6s 10ms/step - loss: 0.0239 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0324 - val_loss: 0.0114\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0266 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0282 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0292 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0289 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0226 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0226 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0265 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0225 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0237 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0271 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0294 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0315 - val_loss: 0.0111\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0131\n",
            "426/426 [==============================] - 7s 4ms/step - loss: 0.0261 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0242 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0242 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0215 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0255 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0280 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0280 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0129\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0231 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0232 - val_loss: 0.0137\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0242 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0255 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0252 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0293 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0273 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0267 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0277 - val_loss: 0.0123\n",
            "426/426 [==============================] - 6s 10ms/step - loss: 0.0227 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0280 - val_loss: 0.0112\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0236 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0279 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0269 - val_loss: 0.0113\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0260 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0262 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0220 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0247 - val_loss: 0.0120\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0242 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0256 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0147\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0232 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0266 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0279 - val_loss: 0.0114\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0228 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0291 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0233 - val_loss: 0.0131\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0217 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0261 - val_loss: 0.0121\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0237 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0236 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0307 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0284 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0227 - val_loss: 0.0138\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0304 - val_loss: 0.0119\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0219 - val_loss: 0.0144\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0213 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0282 - val_loss: 0.0112\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0315 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0252 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0252 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0231 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0253 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0219 - val_loss: 0.0127\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0269 - val_loss: 0.0111\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0238 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0218 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0148\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0259 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0254 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0290 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0270 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0265 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0241 - val_loss: 0.0120\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0284 - val_loss: 0.0112\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0231 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0271 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0236 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0226 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0229 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0266 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0220 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0286 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0132\n",
            "426/426 [==============================] - 6s 10ms/step - loss: 0.0225 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0252 - val_loss: 0.0129\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0246 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0241 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0248 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0290 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0240 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0206 - val_loss: 0.0136\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0255 - val_loss: 0.0125\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0210 - val_loss: 0.0141\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0252 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0252 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0227 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0218 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0263 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0227 - val_loss: 0.0143\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0232 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0223 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0225 - val_loss: 0.0122\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0253 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0217 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0229 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0272 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0285 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0315 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0227 - val_loss: 0.0127\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0253 - val_loss: 0.0117\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0231 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0260 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0242 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0263 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0245 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0305 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0260 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0287 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0247 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0242 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0268 - val_loss: 0.0119\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0277 - val_loss: 0.0120\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0231 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0231 - val_loss: 0.0123\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0233 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0290 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0245 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0257 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0234 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0131\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0216 - val_loss: 0.0136\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0256 - val_loss: 0.0117\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0216 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0249 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0273 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0217 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0290 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 7ms/step - loss: 0.0253 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0143\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0257 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0227 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0279 - val_loss: 0.0115\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0252 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0229 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0272 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0221 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0273 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0141\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0237 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0224 - val_loss: 0.0130\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0228 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0226 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0250 - val_loss: 0.0115\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0215 - val_loss: 0.0131\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0223 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0248 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0220 - val_loss: 0.0145\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0281 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0222 - val_loss: 0.0127\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0284 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0247 - val_loss: 0.0120\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0223 - val_loss: 0.0125\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0258 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0236 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0242 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0224 - val_loss: 0.0131\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0208 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0216 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0250 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0311 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0291 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0214 - val_loss: 0.0131\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0260 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0213 - val_loss: 0.0135\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0254 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0299 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0232 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0321 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0236 - val_loss: 0.0118\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0140\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0132\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0126\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0245 - val_loss: 0.0128\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0252 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0219 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0223 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0214 - val_loss: 0.0129\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0250 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0288 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0253 - val_loss: 0.0122\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0231 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0241 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0282 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0259 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0124\n",
            "426/426 [==============================] - 5s 5ms/step - loss: 0.0218 - val_loss: 0.0125\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0224 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0315 - val_loss: 0.0115\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0265 - val_loss: 0.0113\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0225 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0219 - val_loss: 0.0147\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0242 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0267 - val_loss: 0.0123\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0275 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0254 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0133\n",
            "426/426 [==============================] - 6s 5ms/step - loss: 0.0330 - val_loss: 0.0118\n",
            "426/426 [==============================] - 5s 7ms/step - loss: 0.0240 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0233 - val_loss: 0.0132\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0274 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0239 - val_loss: 0.0119\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0130\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0247 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0222 - val_loss: 0.0135\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0256 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0227 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0232 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0223 - val_loss: 0.0139\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0228 - val_loss: 0.0139\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0230 - val_loss: 0.0133\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0248 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0218 - val_loss: 0.0148\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0236 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0246 - val_loss: 0.0117\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0229 - val_loss: 0.0136\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0259 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0122\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0251 - val_loss: 0.0120\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0228 - val_loss: 0.0144\n",
            "426/426 [==============================] - 3s 3ms/step - loss: 0.0311 - val_loss: 0.0114\n",
            "426/426 [==============================] - 5s 4ms/step - loss: 0.0241 - val_loss: 0.0124\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0270 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0260 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0121\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0238 - val_loss: 0.0118\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0207 - val_loss: 0.0126\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0244 - val_loss: 0.0117\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0220 - val_loss: 0.0139\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0230 - val_loss: 0.0133\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0238 - val_loss: 0.0129\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0225 - val_loss: 0.0137\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0261 - val_loss: 0.0117\n",
            "426/426 [==============================] - 7s 6ms/step - loss: 0.0249 - val_loss: 0.0119\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0244 - val_loss: 0.0128\n",
            "426/426 [==============================] - 4s 4ms/step - loss: 0.0256 - val_loss: 0.0127\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0299 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0121\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0231 - val_loss: 0.0124\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0234 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0218 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0222 - val_loss: 0.0136\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0258 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0231 - val_loss: 0.0134\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0270 - val_loss: 0.0114\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0245 - val_loss: 0.0125\n",
            "426/426 [==============================] - 7s 5ms/step - loss: 0.0288 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0226 - val_loss: 0.0134\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0242 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0239 - val_loss: 0.0126\n",
            "426/426 [==============================] - 4s 5ms/step - loss: 0.0295 - val_loss: 0.0112\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0317 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0128\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0292 - val_loss: 0.0115\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0265 - val_loss: 0.0116\n",
            "426/426 [==============================] - 4s 6ms/step - loss: 0.0298 - val_loss: 0.0116\n",
            "426/426 [==============================] - 3s 5ms/step - loss: 0.0233 - val_loss: 0.0125\n",
            "426/426 [==============================] - 3s 4ms/step - loss: 0.0249 - val_loss: 0.0115\n",
            "426/426 [==============================] - 6s 4ms/step - loss: 0.0252 - val_loss: 0.0116\n",
            "426/426 [==============================] - 5s 6ms/step - loss: 0.0298 - val_loss: 0.0112\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# PSO Optimization\n",
        "lb = [1, 1]  # Lower bounds for epochs and batch_size\n",
        "ub = [1.5, 1.5]  # Upper bounds for epochs and batch_size\n",
        "\n",
        "# PSO optimization using the objective function and bounds\n",
        "best_params, _ = pso(objective_function, lb, ub, args=(x_train, y_train, x_test, y_test))\n",
        "\n",
        "# Use the best parameters to train the final LSTM model with early stopping\n",
        "best_epochs, best_batch_size = best_params\n",
        "final_lstm_model = create_lstm_model((x_train.shape[1], 1))\n",
        "final_lstm_model.fit(x_train, y_train, epochs=int(best_epochs), batch_size=int(best_batch_size), verbose=1,\n",
        "                     validation_data=(x_test, y_test), callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa_2Lb6nMe_8"
      },
      "outputs": [],
      "source": [
        "# Function to create an MLP model\n",
        "def create_mlp_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_581n8QwMlOY",
        "outputId": "4a183f81-4e24-4f35-ad32-ee9e8697a6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 0.1744\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0837\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0554\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0495\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0470\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0449\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0410\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0393\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0376\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0360\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0350\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0337\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0330\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0323\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0318\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0314\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0309\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0307\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0309\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0306\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0306\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0304\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0303\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0304\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0303\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0302\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0306\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0306\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0302\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0302\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0301\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0301\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0299\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0298\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0299\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0299\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0298\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0296\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0293\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0292\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0292\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0291\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0288\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0286\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0283\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0282\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0280\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0277\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0277\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0274\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0273\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0272\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0277\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0268\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0264\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0266\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0266\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0259\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0257\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0257\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0252\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0250\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0246\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0245\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0242\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0241\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0236\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0234\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0231\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0225\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0222\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0220\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0218\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0216\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0214\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0212\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0211\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0206\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0206\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0203\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0199\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0197\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0195\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0195\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0190\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0188\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0186\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0187\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0182\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a575e640fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Train and evaluate the MLP model\n",
        "mlp_model = create_mlp_model(x_train.shape[1])\n",
        "mlp_model.fit(x_train, y_train, epochs=100, batch_size=8, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu0fLHknMqQQ",
        "outputId": "b6e20f9a-930b-4be2-98ac-10504a086e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "For x=2.5:\n",
            "LSTM Predicted y: 3552.8366329669952\n",
            "MLP Predicted y: 3552.8366329669952\n"
          ]
        }
      ],
      "source": [
        "# Example: Predict y for a specific x value using the trained models\n",
        "x_input = np.array([[2.5]])  # Replace with the desired value of x\n",
        "x_input_normalized = scaler_x.transform(x_input)\n",
        "y_lstm_pred_normalized = final_lstm_model.predict(x_input_normalized.reshape(1, 1, 1))[0, 0]\n",
        "y_lstm_pred = scaler_y.inverse_transform([[y_lstm_pred_normalized]])[0, 0]\n",
        "\n",
        "y_mlp_pred_normalized = mlp_model.predict(x_input_normalized)[0, 0]\n",
        "y_mlp_pred = scaler_y.inverse_transform([[y_mlp_pred_normalized]])[0, 0]\n",
        "\n",
        "print(f'For x={x_input[0, 0]}:')\n",
        "print(f'LSTM Predicted y: {y_lstm_pred}')\n",
        "print(f'MLP Predicted y: {y_mlp_pred}')"
      ]
    }
  ]
}